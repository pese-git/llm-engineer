{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645152ac",
   "metadata": {},
   "source": [
    "### Домашнее задание №4\n",
    "\n",
    "\n",
    "**Домашнее задание необходимо предоставить в формате ссылки на Google Collab/Jupyter Notebook с вашими действиями и ключевыми выводами**\n",
    "\n",
    "- 12 сентября 23:59 — мягкий дедлайн  \n",
    "- 19 сентября 23:59 — жесткий дедлайн  \n",
    "- до мягкого дедлайна за работу можно получить 10 баллов, после — 5  \n",
    "- работы, отправленные после 19 августа, могут быть проверены преподавателями до конца курса в формате зачет/не зачет  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee467b2b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c9a3d0",
   "metadata": {},
   "source": [
    "#### Задание 1. Дообучение декодерной модели — 5 баллов\n",
    "\n",
    "1. **Выбор датасета — 0.5 балла**  \n",
    "   - Выберите и загрузите датасет для задачи генерации текста  \n",
    "   - Подходящие варианты:  \n",
    "     - Текстовые корпусы на платформе Hugging Face  \n",
    "     - Ваши собственные данные  \n",
    "\n",
    "2. **Выбор предобученной модели — 0.5 балла**  \n",
    "   - Выберите подходящую (по размеру — от 1B параметров) предобученную языковую модель на Hugging Face Model Hub  \n",
    "\n",
    "3. **Предварительная оценка качества — 1 балл**  \n",
    "   - Соберите небольшую \"корзинку\" тестовых примеров, прогоните их через модель для оценки качества генерации перед дообучением  \n",
    "   - Дополнительно прогоните модель через выбранную вами одну или несколько релевантных задач из lm-evaluation-harness  \n",
    "\n",
    "4. **QLora-дообучение — 2 балла**  \n",
    "   - Настройте параметры дообучения через QLora, опишите свой выбор значений и настраиваемых параметров в комментариях  \n",
    "   - Обучите модель на вашем датасете  \n",
    "\n",
    "5. **Оценка качества обучения — 1 балл**  \n",
    "   - Проверьте качество генерации на бенчмарке и \"корзинке\" после дообучения  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba724b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e86f08b9",
   "metadata": {},
   "source": [
    "#### Задание 2. Дообучение энкодерной модели — 5 баллов\n",
    "\n",
    "1. **Выбор датасета — 0.5 балла**  \n",
    "   - Выберите и загрузите датасет для контрастивного дообучения  \n",
    "   - Подходящие варианты:  \n",
    "     - QA-датасеты  \n",
    "     - Ваши собственные данные — главное, чтобы в них были пары anchor+positive  \n",
    "\n",
    "2. **Выбор предобученной модели — 0.5 балла**  \n",
    "   - Выберите энкодерную модель для дообучения  \n",
    "\n",
    "3. **Предварительная оценка качества — 1 балл**  \n",
    "   - Выделите валидационное множество, проверьте на нем качество поиска с помощью метрик @k  \n",
    "   - Также для валидации можно использовать down-stream задачу на эмбеддингах из модели, если она у вас есть  \n",
    "\n",
    "4. **QLora-дообучение — 2 балла**  \n",
    "   - Настройте параметры дообучения через QLora, опишите свой выбор значений и настраиваемых параметров в комментариях  \n",
    "   - Обучите модель на вашем датасете  \n",
    "\n",
    "5. **Оценка качества обучения — 1 балл**  \n",
    "   - Проверьте качество генерации на валидационном датасете  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a81fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
