{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание №4\n",
    "\n",
    "\n",
    "**Домашнее задание необходимо предоставить в формате ссылки на Google Collab/Jupyter Notebook с вашими действиями и ключевыми выводами**\n",
    "\n",
    "- 12 сентября 23:59 — мягкий дедлайн  \n",
    "- 19 сентября 23:59 — жесткий дедлайн  \n",
    "- до мягкого дедлайна за работу можно получить 10 баллов, после — 5  \n",
    "- работы, отправленные после 19 августа, могут быть проверены преподавателями до конца курса в формате зачет/не зачет  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:12:07.960191Z",
     "iopub.status.busy": "2025-09-10T09:12:07.959303Z",
     "iopub.status.idle": "2025-09-10T09:13:08.159220Z",
     "shell.execute_reply": "2025-09-10T09:13:08.158461Z",
     "shell.execute_reply.started": "2025-09-10T09:12:07.960160Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n",
      "Found existing installation: bitsandbytes 0.47.0\n",
      "Uninstalling bitsandbytes-0.47.0:\n",
      "  Successfully uninstalled bitsandbytes-0.47.0\n",
      "Found existing installation: unsloth 2025.9.3\n",
      "Uninstalling unsloth-2025.9.3:\n",
      "  Successfully uninstalled unsloth-2025.9.3\n",
      "Found existing installation: transformers 4.56.1\n",
      "Uninstalling transformers-4.56.1:\n",
      "  Successfully uninstalled transformers-4.56.1\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.47.0\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: xformers==0.0.29.post3 in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\n",
      "Requirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.29.post3) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.29.post3) (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers==0.0.29.post3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers==0.0.29.post3) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xformers==0.0.29.post3) (2.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers==0.0.29.post3) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers==0.0.29.post3) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xformers==0.0.29.post3) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xformers==0.0.29.post3) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xformers==0.0.29.post3) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xformers==0.0.29.post3) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1) (1.17.0)\n",
      "Using cached transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.56.1\n",
      "Collecting unsloth\n",
      "  Using cached unsloth-2025.9.3-py3-none-any.whl.metadata (52 kB)\n",
      "Using cached unsloth-2025.9.3-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2025.9.3\n",
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2025.9.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchao in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.10.0)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.2.0)\n",
      "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (25.0)\n",
      "Collecting tyro (from unsloth_zoo)\n",
      "  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.56.1)\n",
      "Requirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.8.1)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.23.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.15.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.34.4)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.1.9)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (11.2.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2024.11.6)\n",
      "Collecting msgspec (from unsloth_zoo)\n",
      "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.12.13)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (0.5.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth_zoo) (2.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth_zoo) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.6.15)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth_zoo) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth_zoo) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth_zoo) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth_zoo) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth_zoo) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth_zoo) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth_zoo) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth_zoo) (2024.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (14.0.0)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth_zoo)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\n",
      "Downloading unsloth_zoo-2025.9.4-py3-none-any.whl (206 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "Downloading tyro-0.9.31-py3-none-any.whl (131 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, msgspec, tyro, cut_cross_entropy, unsloth_zoo\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [unsloth_zoo]\u001b[0m [unsloth_zoo]tropy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cut_cross_entropy-25.1.1 msgspec-0.19.0 shtab-1.7.2 tyro-0.9.31 unsloth_zoo-2025.9.4\n",
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 09:12:33.476711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757495553.726259      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757495553.811062      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Torch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "BitsAndBytes ready!\n"
     ]
    }
   ],
   "source": [
    "#!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl\n",
    "#!pip install sentencepiece protobuf \"datasets>=3.4.1\"\n",
    "#!pip install --no-deps unsloth\n",
    "\n",
    "\n",
    "# 1️⃣ Обновляем pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# 2️⃣ Удаляем старые версии проблемных пакетов\n",
    "!pip uninstall -y bitsandbytes unsloth transformers\n",
    "\n",
    "# 3️⃣ Устанавливаем совместимую версию bitsandbytes для CUDA 12.5/12.6\n",
    "!pip install --no-deps bitsandbytes\n",
    "# Устанавливаем BitsAndBytes под CUDA 11.8\n",
    "#!pip install bitsandbytes==0.41.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n",
    "\n",
    "# 4️⃣ Устанавливаем остальные зависимости для unsloth-zoo\n",
    "!pip install accelerate transformers xformers==0.0.29.post3 peft trl sentencepiece protobuf \"datasets>=3.4.1\"\n",
    "\n",
    "# 5️⃣ Устанавливаем сам unsloth (без зависимостей, чтобы не ломать версии)\n",
    "!pip install --no-deps unsloth\n",
    "\n",
    "!pip install unsloth_zoo\n",
    "\n",
    "# 6️⃣ Проверка работы\n",
    "import torch, bitsandbytes as bnb\n",
    "from unsloth.models.loader import FastLanguageModel\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"BitsAndBytes ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:51.374988Z",
     "iopub.status.busy": "2025-09-10T09:18:51.374157Z",
     "iopub.status.idle": "2025-09-10T09:18:51.378637Z",
     "shell.execute_reply": "2025-09-10T09:18:51.377748Z",
     "shell.execute_reply.started": "2025-09-10T09:18:51.374955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Удаляем несовместимый bitsandbytes\n",
    "#!pip uninstall -y bitsandbytes\n",
    "\n",
    "# Устанавливаем BitsAndBytes под CUDA 11.8\n",
    "#!pip install bitsandbytes==0.41.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:51.834274Z",
     "iopub.status.busy": "2025-09-10T09:18:51.834023Z",
     "iopub.status.idle": "2025-09-10T09:18:51.839184Z",
     "shell.execute_reply": "2025-09-10T09:18:51.838334Z",
     "shell.execute_reply.started": "2025-09-10T09:18:51.834257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitsAndBytes imported!\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "print(\"BitsAndBytes imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:55.614577Z",
     "iopub.status.busy": "2025-09-10T09:18:55.613819Z",
     "iopub.status.idle": "2025-09-10T09:18:55.618246Z",
     "shell.execute_reply": "2025-09-10T09:18:55.617436Z",
     "shell.execute_reply.started": "2025-09-10T09:18:55.614553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\"\n",
    "os.environ[\"DISABLE_TRITON\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:56.327126Z",
     "iopub.status.busy": "2025-09-10T09:18:56.326876Z",
     "iopub.status.idle": "2025-09-10T09:18:56.331564Z",
     "shell.execute_reply": "2025-09-10T09:18:56.330740Z",
     "shell.execute_reply.started": "2025-09-10T09:18:56.327108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:57.954647Z",
     "iopub.status.busy": "2025-09-10T09:18:57.953945Z",
     "iopub.status.idle": "2025-09-10T09:18:58.379101Z",
     "shell.execute_reply": "2025-09-10T09:18:58.378228Z",
     "shell.execute_reply.started": "2025-09-10T09:18:57.954607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n",
      "Wed Sep 10 09:18:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0             34W /  250W |     257MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:18:59.856130Z",
     "iopub.status.busy": "2025-09-10T09:18:59.855328Z",
     "iopub.status.idle": "2025-09-10T09:18:59.860702Z",
     "shell.execute_reply": "2025-09-10T09:18:59.859908Z",
     "shell.execute_reply.started": "2025-09-10T09:18:59.856097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitsAndBytes ready!\n"
     ]
    }
   ],
   "source": [
    "import torch, bitsandbytes as bnb\n",
    "print(\"BitsAndBytes ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:01.487992Z",
     "iopub.status.busy": "2025-09-10T09:19:01.487214Z",
     "iopub.status.idle": "2025-09-10T09:19:01.492884Z",
     "shell.execute_reply": "2025-09-10T09:19:01.492159Z",
     "shell.execute_reply.started": "2025-09-10T09:19:01.487963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Device: Tesla P100-PCIE-16GB\n",
      "BitsAndBytes version: 0.47.0\n"
     ]
    }
   ],
   "source": [
    "import torch, bitsandbytes as bnb\n",
    "from unsloth.models.loader import FastLanguageModel\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "print(\"BitsAndBytes version:\", bnb.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:02.486729Z",
     "iopub.status.busy": "2025-09-10T09:19:02.486020Z",
     "iopub.status.idle": "2025-09-10T09:19:02.491249Z",
     "shell.execute_reply": "2025-09-10T09:19:02.490537Z",
     "shell.execute_reply.started": "2025-09-10T09:19:02.486702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True Device: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "#import torch, bitsandbytes as bnb, unsloth\n",
    "import torch, bitsandbytes as bnb\n",
    "from unsloth.models.loader import FastLanguageModel\n",
    "\n",
    "print(\"CUDA:\", torch.cuda.is_available(), \"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:04.347430Z",
     "iopub.status.busy": "2025-09-10T09:19:04.346870Z",
     "iopub.status.idle": "2025-09-10T09:19:04.351487Z",
     "shell.execute_reply": "2025-09-10T09:19:04.350778Z",
     "shell.execute_reply.started": "2025-09-10T09:19:04.347405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc, os, math, random\n",
    "import pynvml\n",
    "from datasets import Dataset, load_dataset\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:04.875140Z",
     "iopub.status.busy": "2025-09-10T09:19:04.874898Z",
     "iopub.status.idle": "2025-09-10T09:19:04.881586Z",
     "shell.execute_reply": "2025-09-10T09:19:04.880852Z",
     "shell.execute_reply.started": "2025-09-10T09:19:04.875124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:05.394610Z",
     "iopub.status.busy": "2025-09-10T09:19:05.394295Z",
     "iopub.status.idle": "2025-09-10T09:19:06.023303Z",
     "shell.execute_reply": "2025-09-10T09:19:06.022275Z",
     "shell.execute_reply.started": "2025-09-10T09:19:05.394587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fresh] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n",
      "NVML used=0.36GB / total=16.00GB\n"
     ]
    }
   ],
   "source": [
    "# --- фикс для P100 ---\n",
    "if hasattr(torch, \"compile\"):\n",
    "    torch.compile = lambda *args, **kwargs: args[0]\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\"\n",
    "os.environ[\"DISABLE_TRITON\"] = \"1\"\n",
    "\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def gpu_mem(note=\"\"):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(f\"[{note}] No CUDA available.\")\n",
    "        return\n",
    "    torch.cuda.synchronize()\n",
    "    alloc = torch.cuda.memory_allocated() / (1024**3)\n",
    "    resrv = torch.cuda.memory_reserved() / (1024**3)\n",
    "    peak = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "    print(f\"[{note}] allocated={alloc:.2f}GB, reserved={resrv:.2f}GB, peak={peak:.2f}GB\")\n",
    "\n",
    "def nvidia_mem():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    pynvml.nvmlInit()\n",
    "    h = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(h)\n",
    "    print(f\"NVML used={info.used/(1024**3):.2f}GB / total={info.total/(1024**3):.2f}GB\")\n",
    "\n",
    "flush()\n",
    "gpu_mem(\"fresh\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1. Дообучение декодерной модели — 5 баллов\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Выбор датасета — 0.5 балла**  \n",
    "   - Выберите и загрузите датасет для задачи генерации текста  \n",
    "   - Подходящие варианты:  \n",
    "     - Текстовые корпусы на платформе Hugging Face  \n",
    "     - Ваши собственные данные  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дообучения модели будем использовать датасет Felladrin/ChatML-aya_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "датасет Felladrin/ChatML-aya_dataset следует [шаблону](https://huggingface.co/docs/transformers/en/chat_templating):\n",
    "\n",
    "```\n",
    "<|im_start|>user\n",
    "Hi there!<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Nice to meet you!<|im_end|>\n",
    "<|im_start|>user\n",
    "Can I ask a question?<|im_end|>\n",
    "```\n",
    "\n",
    "Поэтому нам ничего делать не надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:08.954869Z",
     "iopub.status.busy": "2025-09-10T09:19:08.954073Z",
     "iopub.status.idle": "2025-09-10T09:19:08.959288Z",
     "shell.execute_reply": "2025-09-10T09:19:08.958668Z",
     "shell.execute_reply.started": "2025-09-10T09:19:08.954845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    parts = []\n",
    "    for turn in example[\"conversation\"]:\n",
    "        role = turn[\"role\"]\n",
    "        content = turn[\"content\"].strip()\n",
    "        if role == \"user\":\n",
    "            parts.append(\"<|im_start|>user\")\n",
    "            parts.append(f\"{content}<|im_end|>\")\n",
    "        elif role == \"assistant\":\n",
    "            parts.append(\"<|im_start|>assistant\")\n",
    "            parts.append(f\"{content}<|im_end|>\")\n",
    "    return {\"text\": \"\\n\".join(parts) + \"\\n\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:09.066120Z",
     "iopub.status.busy": "2025-09-10T09:19:09.065661Z",
     "iopub.status.idle": "2025-09-10T09:19:09.069706Z",
     "shell.execute_reply": "2025-09-10T09:19:09.069045Z",
     "shell.execute_reply.started": "2025-09-10T09:19:09.066100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat = { \"conversation\": [\n",
    "  {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"How can I help you today?\"},\n",
    "  {\"role\": \"user\", \"content\": \"I dont know!\"},\n",
    "]}\n",
    "\n",
    "assert formatting_func(chat)[\"text\"] == '<|im_start|>user\\nHello!<|im_end|>\\n<|im_start|>assistant\\nHow can I help you today?<|im_end|>\\n<|im_start|>user\\nI dont know!<|im_end|>\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:09.225771Z",
     "iopub.status.busy": "2025-09-10T09:19:09.225584Z",
     "iopub.status.idle": "2025-09-10T09:19:12.672024Z",
     "shell.execute_reply": "2025-09-10T09:19:12.671471Z",
     "shell.execute_reply.started": "2025-09-10T09:19:09.225757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8db4160a434f13a27fbcf0d8ee5551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b583225ae2d4cb78dd73add293543d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/132M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcebe0477084e3cbe62d36f80398e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/202364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'language', 'language_code', 'annotation_type', 'user_id'],\n",
       "    num_rows: 202364\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "fell_dataset = load_dataset(\"Felladrin/ChatML-aya_dataset\", split=\"train\")\n",
    "#fell_dataset = fell_dataset.map(formatting_func)\n",
    "fell_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:12.673266Z",
     "iopub.status.busy": "2025-09-10T09:19:12.673009Z",
     "iopub.status.idle": "2025-09-10T09:19:14.622390Z",
     "shell.execute_reply": "2025-09-10T09:19:14.621514Z",
     "shell.execute_reply.started": "2025-09-10T09:19:12.673248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b258907efd5d4c42b55092908abd8882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/202364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего примеров: 202364\n",
      "Русских примеров: 423\n",
      "Доля русских: 0.21%\n"
     ]
    }
   ],
   "source": [
    "# всего строк\n",
    "total = len(fell_dataset)\n",
    "\n",
    "# фильтруем только русские\n",
    "ru_dataset = fell_dataset.filter(lambda x: x[\"language_code\"] == \"rus\")\n",
    "ru_total = len(ru_dataset)\n",
    "\n",
    "# считаем долю\n",
    "share = ru_total / total * 100\n",
    "\n",
    "print(f\"Всего примеров: {total}\")\n",
    "print(f\"Русских примеров: {ru_total}\")\n",
    "print(f\"Доля русских: {share:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:14.623542Z",
     "iopub.status.busy": "2025-09-10T09:19:14.623236Z",
     "iopub.status.idle": "2025-09-10T09:19:14.632270Z",
     "shell.execute_reply": "2025-09-10T09:19:14.631616Z",
     "shell.execute_reply.started": "2025-09-10T09:19:14.623513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'language', 'language_code', 'annotation_type', 'user_id'],\n",
      "    num_rows: 423\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# только по коду\n",
    "ru_dataset = fell_dataset.filter(lambda x: x[\"language_code\"] == \"rus\")\n",
    "\n",
    "print(ru_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:14.634640Z",
     "iopub.status.busy": "2025-09-10T09:19:14.634398Z",
     "iopub.status.idle": "2025-09-10T09:19:14.649512Z",
     "shell.execute_reply": "2025-09-10T09:19:14.648857Z",
     "shell.execute_reply.started": "2025-09-10T09:19:14.634616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotation_type': 're-annotations',\n",
      " 'language': 'Russian',\n",
      " 'language_code': 'rus',\n",
      " 'text': '<|im_start|>user\\n'\n",
      "         'В чём заключается основная причина холодной войны?<|im_end|>\\n'\n",
      "         '<|im_start|>assistant\\n'\n",
      "         'Одной из ключевых причин холодной войны стал конфликт между '\n",
      "         'демократическими принципами, которые отстаивали США, и '\n",
      "         'коммунистической идеологией, которой придерживался СССР. '\n",
      "         'Противостояние этих сверхдержав во многом определило политическую и '\n",
      "         'военную динамику на мировой арене на протяжении долгого периода '\n",
      "         'времени.<|im_end|>\\n',\n",
      " 'user_id': '948c9f2f1e0a97c7c9b4097583fb652d0ea893bfa5e92fa343fb1487f34a700b'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'annotation_type': 're-annotations',\n",
      " 'language': 'Russian',\n",
      " 'language_code': 'rus',\n",
      " 'text': '<|im_start|>user\\n'\n",
      "         'Реши задачу: Пятеро молодых рабочих получили на всех зарплату - 1500 '\n",
      "         'рублей. Каждый из них хочет купить себе магнитофон ценой 320 рублей. '\n",
      "         'Докажите, что кому-то из них придется подождать с покупкой до '\n",
      "         'следующей зарплаты.<|im_end|>\\n'\n",
      "         '<|im_start|>assistant\\n'\n",
      "         'Решение: Если бы каждый из рабочих мог купить магнитофон, то у них в '\n",
      "         'сумме было бы не менее 5 · 320 = 1600 рублей. Но так как у них '\n",
      "         'только 1500 рублей, это означает что им не хватает 100 рублей чтобы '\n",
      "         'каждый смог совершить покупку. Таким образом, кому то из них '\n",
      "         'придется подождать до следующей зарплаты.<|im_end|>\\n',\n",
      " 'user_id': '063f716f3bcabd862b523a8a607b9ecbb0c9030d98c02069c3a9b06165a7092b'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'annotation_type': 're-annotations',\n",
      " 'language': 'Russian',\n",
      " 'language_code': 'rus',\n",
      " 'text': '<|im_start|>user\\n'\n",
      "         'Торговля наркотиками в Таджикистане<|im_end|>\\n'\n",
      "         '<|im_start|>assistant\\n'\n",
      "         'Торговля наркотиками является основным незаконным источником дохода '\n",
      "         'в Таджикистане, поскольку это важная транзитная страна для афганских '\n",
      "         'наркотиков, предназначенных для российских и, в меньшей степени, '\n",
      "         'западноевропейских рынков; некоторые опиумные маки также '\n",
      "         'выращиваются на местном уровне для внутреннего рынка. Однако '\n",
      "         'благодаря все большей помощи со стороны международных организаций, '\n",
      "         'таких как УНП ООН, и сотрудничеству с властями США, России, ЕС и '\n",
      "         'Афганистана достигается определенный прогресс в борьбе с незаконным '\n",
      "         'оборотом наркотиков. Таджикистан занимает третье место в мире по '\n",
      "         'конфискации героина и опиума (1216,3 кг героина и 267,8 кг опиума в '\n",
      "         'первой половине 2006 года). Деньги от наркотиков коррумпируют '\n",
      "         'правительство страны; по мнению некоторых экспертов, известные '\n",
      "         'личности, которые воевали на обеих сторонах гражданской войны и '\n",
      "         'занимали посты в правительстве после подписания перемирия, теперь '\n",
      "         'вовлечены в торговлю наркотиками. УНП ООН работает с Таджикистаном '\n",
      "         'над укреплением пограничных переходов, обучением и созданием '\n",
      "         'совместных групп по пресечению преступлений. Он также помог создать '\n",
      "         'Агентство по контролю за наркотиками Таджикистана.<|im_end|>\\n',\n",
      " 'user_id': '3e3c95d3335858a104eed4e19ccced346445bbe66231b40a987711aae719d937'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for i in range(3):\n",
    "    pprint(ru_dataset[i])\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Выбор предобученной модели — 0.5 балла**  \n",
    "   - Выберите подходящую (по размеру — от 1B параметров) предобученную языковую модель на Hugging Face Model Hub  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:19:14.650343Z",
     "iopub.status.busy": "2025-09-10T09:19:14.650149Z",
     "iopub.status.idle": "2025-09-10T09:20:18.341057Z",
     "shell.execute_reply": "2025-09-10T09:20:18.339731Z",
     "shell.execute_reply.started": "2025-09-10T09:19:14.650328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Qwen2.5-1.5B'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Total 58 (delta 0), reused 0 (delta 0), pack-reused 58 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (58/58), 3.61 MiB | 6.60 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/unsloth/Qwen2.5-1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:20:18.343037Z",
     "iopub.status.busy": "2025-09-10T09:20:18.342663Z",
     "iopub.status.idle": "2025-09-10T09:20:35.427429Z",
     "shell.execute_reply": "2025-09-10T09:20:35.426520Z",
     "shell.execute_reply.started": "2025-09-10T09:20:18.342995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[before load QLoRA] allocated=0.00GB, reserved=0.00GB, peak=0.00GB\n",
      "==((====))==  Unsloth 2025.9.3: Fast Qwen2 patching. Transformers: 4.56.1.\n",
      "   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.9.3 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[after load QLoRA] allocated=1.16GB, reserved=1.57GB, peak=1.45GB\n",
      "NVML used=1.98GB / total=16.00GB\n"
     ]
    }
   ],
   "source": [
    "# Указываем название модели и максимальную длину последовательности\n",
    "model_name = \"Qwen2.5-1.5B\"\n",
    "max_seq_length = 1024\n",
    "\n",
    "# Очистка памяти GPU перед загрузкой модели\n",
    "flush()\n",
    "gpu_mem(\"before load QLoRA\")\n",
    "\n",
    "# Загружаем предобученную модель с поддержкой QLoRA\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,          # используем стандартный dtype (float16/float32)\n",
    "    load_in_4bit=True,   # включаем загрузку весов в 4-битном формате (QLoRA)\n",
    ")\n",
    "\n",
    "# Опционально: можно подготовить модель к обучению с градиентным чекпоинтингом\n",
    "# и без компиляции TorchDynamo (выключено закомментировано)\n",
    "# FastLanguageModel.for_training(model, use_gradient_checkpointing=True, torch_compile=False)\n",
    "\n",
    "# Применяем PEFT (LoRA) для обучения модели с низкоразмерными адаптивными весами\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,                                # ранг матриц LoRA\n",
    "    lora_alpha=16,                       # коэффициент масштабирования LoRA\n",
    "    lora_dropout=0.05,                    # вероятность дропаута в LoRA слоях\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],  # какие модули адаптировать LoRA\n",
    "    use_gradient_checkpointing=\"unsloth\",  # включаем градиентный чекпоинтинг для экономии памяти\n",
    ")\n",
    "\n",
    "# Проверяем память GPU после загрузки QLoRA\n",
    "gpu_mem(\"after load QLoRA\")\n",
    "nvidia_mem()  # выводим текущую загрузку видеопамяти NVIDIA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Предварительная оценка качества — 1 балл**  \n",
    "   - Соберите небольшую \"корзинку\" тестовых примеров, прогоните их через модель для оценки качества генерации перед дообучением  \n",
    "   - Дополнительно прогоните модель через выбранную вами одну или несколько релевантных задач из lm-evaluation-harness  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим модель в диалоговом сценарии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:20:35.428571Z",
     "iopub.status.busy": "2025-09-10T09:20:35.428311Z",
     "iopub.status.idle": "2025-09-10T09:20:35.434106Z",
     "shell.execute_reply": "2025-09-10T09:20:35.433337Z",
     "shell.execute_reply.started": "2025-09-10T09:20:35.428553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_answer(prompt):\n",
    "    # 1. Формируем диалоговый шаблон для модели Qwen\n",
    "    #    - role=\"user\" обозначает, что это сообщение от пользователя\n",
    "    #    - add_generation_prompt=True добавляет токены для генерации ответа\n",
    "    dialog = qwen_tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # 2. Токенизируем диалог в тензоры PyTorch и переносим на GPU\n",
    "    inputs = qwen_tokenizer(dialog, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # 3. Генерируем ответ модели\n",
    "    #    - max_new_tokens=100 ограничивает длину ответа\n",
    "    #    - use_cache=True ускоряет генерацию\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100, use_cache=True)\n",
    "\n",
    "    # 4. Декодируем сгенерированные токены обратно в текст\n",
    "    #    - берем все после слова \"assistant\" чтобы получить ответ модели\n",
    "    return tokenizer.batch_decode(outputs)[0].split(\"assistant\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:20:35.435214Z",
     "iopub.status.busy": "2025-09-10T09:20:35.434975Z",
     "iopub.status.idle": "2025-09-10T09:20:36.786044Z",
     "shell.execute_reply": "2025-09-10T09:20:36.785470Z",
     "shell.execute_reply.started": "2025-09-10T09:20:35.435190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ebb585300e4eaa87435224c764945b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e94b1d92fd4ee4913752c73571085e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d445f1ba1eca4c8fb30c60d353d19884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e999fd9a61d64cba909e8347dfb1378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Переводим модель в режим инференса (выключаем градиенты, отключаем обучение)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Загружаем токенизатор для модели Qwen2.5-7B\n",
    "# Этот токенизатор нужен для преобразования текста в токены и обратно\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:20:36.786968Z",
     "iopub.status.busy": "2025-09-10T09:20:36.786758Z",
     "iopub.status.idle": "2025-09-10T09:20:36.790960Z",
     "shell.execute_reply": "2025-09-10T09:20:36.790043Z",
     "shell.execute_reply.started": "2025-09-10T09:20:36.786952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompts_for_test = [\n",
    "    'Какая основная причина холодной войны?',\n",
    "    'Страна рождения Ньютона?',\n",
    "    'Что значит выражение \"окно в Европу',\n",
    "    'Расположение Речи Посполитой?',\n",
    "    'Сочини короткую захватывающую криминальную историю с неожиданным концом'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:20:36.794829Z",
     "iopub.status.busy": "2025-09-10T09:20:36.794556Z",
     "iopub.status.idle": "2025-09-10T09:21:11.828649Z",
     "shell.execute_reply": "2025-09-10T09:21:11.827865Z",
     "shell.execute_reply.started": "2025-09-10T09:20:36.794806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Какая основная причина холодной войны?<|endoftext|>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Страна рождения Лейбинга?猞\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Что\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Расположение Речи Посполитой?猞сия\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Сочини короткую захватывающую криминальную историю с неожиданным концом\n",
      "Сочини короткую захватывающую криминальную историю с неожиданным концом\n",
      "Сочини короткую захватывающую криминальную историю с неожиданным концом\n",
      "Сочини короткую захват\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Проходим по каждому тексту из списка prompts_for_test\n",
    "for text in prompts_for_test:\n",
    "    # Генерируем ответ модели на данный текст и выводим его\n",
    "    print(generate_answer(text))\n",
    "    \n",
    "    # Выводим разделитель для удобного чтения результатов\n",
    "    print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовим бенчмарк для трекинга качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем для замеров бенчмарк [LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)\n",
    "\n",
    "LM Evaluation Harness поддерживает более 60 стандартных академических бенчмарков с сотнями подзадач и вариантов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:21:11.830214Z",
     "iopub.status.busy": "2025-09-10T09:21:11.829524Z",
     "iopub.status.idle": "2025-09-10T09:21:31.600897Z",
     "shell.execute_reply": "2025-09-10T09:21:31.599985Z",
     "shell.execute_reply.started": "2025-09-10T09:21:11.830187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!git clone --depth 1 https://github.com/EleutherAI/lm-evaluation-harness\n",
    "!cd lm-evaluation-harness && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:21:31.602246Z",
     "iopub.status.busy": "2025-09-10T09:21:31.602003Z",
     "iopub.status.idle": "2025-09-10T09:22:00.201054Z",
     "shell.execute_reply": "2025-09-10T09:22:00.200254Z",
     "shell.execute_reply.started": "2025-09-10T09:21:31.602220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lm-evaluation-harness'...\n",
      "remote: Enumerating objects: 56807, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 56807 (delta 3), reused 2 (delta 2), pack-reused 56799 (from 3)\u001b[K\n",
      "Receiving objects: 100% (56807/56807), 31.65 MiB | 22.24 MiB/s, done.\n",
      "Resolving deltas: 100% (39220/39220), done.\n",
      "error: pathspec '6b5ac77' did not match any file(s) known to git\n",
      "Obtaining file:///kaggle/working/lm-evaluation-harness\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (1.8.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.4.5)\n",
      "Requirement already satisfied: datasets<4.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (3.6.0)\n",
      "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (2.11.0)\n",
      "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.15.2)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (1.2.2)\n",
      "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (4.56.1)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.23.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (0.3.8)\n",
      "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (1.1)\n",
      "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm_eval==0.4.9.1) (10.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (19.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (3.12.13)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.9.1) (7.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.9.1) (0.5.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2025.6.15)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.1) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.1) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.1) (1.17.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.1) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.1) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.1) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.1) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.1) (5.4.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.1) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.1) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.1) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm_eval==0.4.9.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm_eval==0.4.9.1) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm_eval==0.4.9.1) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm_eval==0.4.9.1) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2024.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.9.1) (8.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0,>=2.16.0->lm_eval==0.4.9.1) (2025.2)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (75.2.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (3.3.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm_eval==0.4.9.1) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.9.1) (1.3.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.9.1) (5.2.0)\n",
      "Building wheels for collected packages: lm_eval\n",
      "  Building editable for lm_eval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lm_eval: filename=lm_eval-0.4.9.1-0.editable-py3-none-any.whl size=27214 sha256=be5d2af2c5b29e0934fccec1916542de386a4c489dea0bf12d486667ec66447a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hw573xr5/wheels/77/55/e2/f4fd55d2524a31cbb6785f406430894b7ff865f964e5ada5e9\n",
      "Successfully built lm_eval\n",
      "Installing collected packages: lm_eval\n",
      "  Attempting uninstall: lm_eval\n",
      "    Found existing installation: lm_eval 0.4.9.1\n",
      "    Uninstalling lm_eval-0.4.9.1:\n",
      "      Successfully uninstalled lm_eval-0.4.9.1\n",
      "Successfully installed lm_eval-0.4.9.1\n"
     ]
    }
   ],
   "source": [
    "!rm -rf lm-evaluation-harness\n",
    "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "!cd lm-evaluation-harness && git checkout 6b5ac77   # июль 2024, стабильный\n",
    "!cd lm-evaluation-harness && pip install -e .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:22:00.202464Z",
     "iopub.status.busy": "2025-09-10T09:22:00.202129Z",
     "iopub.status.idle": "2025-09-10T09:22:05.451653Z",
     "shell.execute_reply": "2025-09-10T09:22:05.450683Z",
     "shell.execute_reply.started": "2025-09-10T09:22:00.202426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lm_eval 0.4.9.1\n",
      "Uninstalling lm_eval-0.4.9.1:\n",
      "  Successfully uninstalled lm_eval-0.4.9.1\n",
      "Collecting lm-eval==0.4.2\n",
      "  Downloading lm_eval-0.4.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (1.8.1)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.4.5)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (3.6.0)\n",
      "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (2.11.0)\n",
      "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.15.2)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (1.2.2)\n",
      "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (4.56.1)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.23.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (0.3.8)\n",
      "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (1.1)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval==0.4.2) (10.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2) (0.5.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (19.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->lm-eval==0.4.2) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.21.0->lm-eval==0.4.2) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.21.0->lm-eval==0.4.2) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval==0.4.2) (2025.6.15)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2) (1.17.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2) (5.4.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval==0.4.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval==0.4.2) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval==0.4.2) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm-eval==0.4.2) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.21.0->lm-eval==0.4.2) (2024.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval==0.4.2) (8.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval==0.4.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval==0.4.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval==0.4.2) (2025.2)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (75.2.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (3.3.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval==0.4.2) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.2) (1.3.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.2) (5.2.0)\n",
      "Downloading lm_eval-0.4.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lm-eval\n",
      "Successfully installed lm-eval-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y lm-eval\n",
    "!pip install lm-eval==0.4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код запускает **оценку модели** с помощью `lm-evaluation-harness`:\n",
    "\n",
    "```bash\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=Qwen2.5-1.5B,dtype=\"float\" \\\n",
    "    --tasks truthfulqa_ru_mc1 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto:4\n",
    "```\n",
    "\n",
    "1. `lm_eval` — командная утилита для запуска оценки языковых моделей.\n",
    "2. `--model hf` — указывает, что модель загружается из Hugging Face (`hf` = Hugging Face).\n",
    "3. `--model_args pretrained=Qwen2.5-1.5B,dtype=\"float\"` — аргументы для модели:\n",
    "\n",
    "   * `pretrained=Qwen2.5-1.5B` — имя предобученной модели.\n",
    "   * `dtype=\"float\"` — тип данных для весов модели (например, `float32`).\n",
    "4. `--tasks truthfulqa_ru_mc1` — задача для оценки, в данном случае **TruthfulQA на русском с множественным выбором** (`mc1`).\n",
    "5. `--device cuda:0` — использовать **первый GPU** для инференса.\n",
    "6. `--batch_size auto:4` — автоматически подобрать оптимальный размер батча, максимум **4 примера за шаг**.\n",
    "\n",
    "💡 Итого, этот код тестирует Qwen2.5-1.5B на русском TruthfulQA, вычисляя точность ответов с использованием GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:22:05.453244Z",
     "iopub.status.busy": "2025-09-10T09:22:05.452942Z",
     "iopub.status.idle": "2025-09-10T09:22:05.459662Z",
     "shell.execute_reply": "2025-09-10T09:22:05.458693Z",
     "shell.execute_reply.started": "2025-09-10T09:22:05.453217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_lmeh.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_lmeh.sh\n",
    "\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=Qwen2.5-1.5B,dtype=\"float\" \\\n",
    "    --tasks truthfulqa_ru_mc1 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:22:05.460721Z",
     "iopub.status.busy": "2025-09-10T09:22:05.460544Z",
     "iopub.status.idle": "2025-09-10T09:30:23.133741Z",
     "shell.execute_reply": "2025-09-10T09:30:23.132693Z",
     "shell.execute_reply.started": "2025-09-10T09:22:05.460708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 09:22:10.368525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757496130.391223     365 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757496130.398107     365 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Downloading builder script: 5.67kB [00:00, 15.3MB/s]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "README.md: 3.45kB [00:00, 17.6MB/s]\n",
      "data/ru/val.jsonl: 100%|███████████████████| 2.84M/2.84M [00:00<00:00, 3.79MB/s]\n",
      "Generating val split: 100%|█████████| 788/788 [00:00<00:00, 40104.25 examples/s]\n",
      "Map: 100%|███████████████████████████| 788/788 [00:00<00:00, 6420.78 examples/s]\n",
      "100%|██████████████████████████████████████| 788/788 [00:00<00:00, 83922.29it/s]\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 16\n",
      "Running loglikelihood requests:  24%|█▉      | 962/3961 [02:06<04:56, 10.10it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  25%|█▉      | 977/3961 [02:16<04:55, 10.10it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests:  49%|███▍   | 1959/3961 [03:59<03:06, 10.72it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|███▍   | 1974/3961 [04:15<03:05, 10.72it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests:  75%|█████▏ | 2952/3961 [05:46<01:32, 10.92it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 16\n",
      "Running loglikelihood requests:  99%|██████▉| 3932/3961 [07:29<00:02, 11.48it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests: 100%|██████▉| 3947/3961 [07:45<00:01, 11.48it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests: 100%|███████| 3961/3961 [07:48<00:00,  8.46it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /kaggle)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "hf (pretrained=Qwen2.5-1.5B,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (16,16,16,16,16)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |0.2982|±  |0.0163|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash run_lmeh.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **QLora-дообучение — 2 балла**  \n",
    "   - Настройте параметры дообучения через QLora, опишите свой выбор значений и настраиваемых параметров в комментариях  \n",
    "   - Обучите модель на вашем датасете  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Таблица параметров обучения с QLoRA\n",
    "\n",
    "| Параметр                            | Значение                                                                        | Обоснование                                                                                          |\n",
    "| ----------------------------------- | ------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| **load\\_in\\_4bit**                  | `True`                                                                          | Используется 4-битное квантование QLoRA для значительной экономии GPU-памяти.                        |\n",
    "| **dtype**                           | `None`                                                                          | Выбирается автоматически (обычно float16/bfloat16), так как QLoRA уже оптимизирует память.           |\n",
    "| **max\\_seq\\_length**                | (задаётся)                                                                      | Ограничение длины входной последовательности, баланс между качеством и ресурсами.                    |\n",
    "| **r (LoRA rank)**                   | `16`                                                                            | Размерность низкоранговых матриц. Стандартное значение, обеспечивающее компромисс «качество/память». |\n",
    "| **lora\\_alpha**                     | `16`                                                                            | Коэффициент масштабирования LoRA. Установлен равным `r`, что обеспечивает стабильность.              |\n",
    "| **lora\\_dropout**                   | `0.05`                                                                          | Небольшой дропаут для предотвращения переобучения на ограниченном датасете.                          |\n",
    "| **target\\_modules**                 | `[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]` | Основные линейные проекции в архитектуре трансформера, куда добавляются LoRA-адаптеры.               |\n",
    "| **use\\_gradient\\_checkpointing**    | `\"unsloth\"`                                                                     | Включён градиентный чекпоинтинг для экономии памяти при обучении.                                    |\n",
    "| **fp16**                            | `True`                                                                          | Смешанная точность (half precision) для ускорения обучения и снижения VRAM.                          |\n",
    "| **per\\_device\\_train\\_batch\\_size** | `4`                                                                             | Небольшой батч, ограниченный объёмом GPU-памяти.                                                     |\n",
    "| **gradient\\_accumulation\\_steps**   | `4`                                                                             | Аккумуляция градиентов имитирует батч размером 16, повышая стабильность обучения.                    |\n",
    "| **warmup\\_steps**                   | `30`                                                                            | Постепенный разгон learning rate в начале обучения, предотвращает резкие скачки градиентов.          |\n",
    "| **num\\_train\\_epochs**              | `1`                                                                             | Минимальное количество эпох для тестового дообучения.                                                |\n",
    "| **max\\_steps**                      | `100`                                                                           | Ограничение количества шагов для быстрого эксперимента.                                              |\n",
    "| **learning\\_rate**                  | `2e-3`                                                                          | Увеличенный LR, так как обучаются только LoRA-адаптеры (малое число параметров).                     |\n",
    "| **logging\\_steps**                  | `1`                                                                             | Логирование после каждого шага для подробного мониторинга.                                           |\n",
    "| **optim**                           | `\"adamw_8bit\"`                                                                  | Оптимизатор AdamW в 8-битном формате (`bitsandbytes`) для экономии VRAM.                             |\n",
    "| **weight\\_decay**                   | `0.01`                                                                          | Регуляризация для уменьшения переобучения.                                                           |\n",
    "| **lr\\_scheduler\\_type**             | `\"linear\"`                                                                      | Линейное уменьшение learning rate — простой и надёжный вариант.                                      |\n",
    "| **seed**                            | `123`                                                                           | Фиксированное значение seed для воспроизводимости.                                                   |\n",
    "| **output\\_dir**                     | `\"outputs\"`                                                                     | Каталог для сохранения модели, чекпоинтов и логов.                                                   |\n",
    "| **report\\_to**                      | `\"none\"`                                                                        | Логи не отправляются во внешние сервисы (например, WandB).                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обоснование выбора параметров QLoRA-обучения\n",
    "\n",
    "Для дообучения декодерной модели использовался метод **QLoRA**, который позволяет эффективно обучать большие языковые модели с ограниченными ресурсами за счёт 4-битного квантования весов и обучения только небольших адаптеров LoRA. Ниже приведено обоснование ключевых параметров:\n",
    "\n",
    "1. **Квантование весов**\n",
    "   Модель загружалась с параметром `load_in_4bit=True`. Это позволило значительно снизить использование GPU-памяти, сохранив при этом качество обучения. Тип чисел (`dtype=None`) оставлен по умолчанию, чтобы фреймворк автоматически выбрал оптимальный формат (обычно float16 или bfloat16).\n",
    "\n",
    "2. **LoRA-адаптеры**\n",
    "\n",
    "   * `r=16` и `lora_alpha=16` — стандартные значения, обеспечивающие баланс между качеством и количеством обучаемых параметров.\n",
    "   * `lora_dropout=0.05` добавляет лёгкую регуляризацию, чтобы модель не переобучалась на ограниченном датасете.\n",
    "   * В `target_modules` выбраны все ключевые проекции (q, k, v, o, а также gate, up, down), так как именно они определяют качество внимания и способность модели адаптироваться под новые данные.\n",
    "\n",
    "3. **Оптимизация памяти**\n",
    "   Для экономии видеопамяти включён **градиентный чекпоинтинг** (`use_gradient_checkpointing=\"unsloth\"`). Это замедляет обучение, но позволяет обучать более длинные последовательности и большие модели на ограниченной GPU. Также использован оптимизатор `adamw_8bit`, который работает с 8-битными градиентами, что дополнительно снижает нагрузку на память.\n",
    "\n",
    "4. **Гиперпараметры обучения**\n",
    "\n",
    "   * **fp16=True** — обучение в смешанной точности для ускорения и снижения VRAM.\n",
    "   * **per\\_device\\_train\\_batch\\_size=4** и **gradient\\_accumulation\\_steps=4**: реальный батч небольшой из-за ограничений GPU, но за счёт аккумуляции градиентов модель обучается так, как будто батч равен 16.\n",
    "   * **learning\\_rate=2e-3** — более высокий шаг обучения по сравнению с полным fine-tuning, так как обучается только небольшой набор параметров LoRA.\n",
    "   * **warmup\\_steps=30** — разогрев learning rate для предотвращения резких скачков градиентов в начале.\n",
    "   * **weight\\_decay=0.01** — лёгкая регуляризация для улучшения обобщающей способности.\n",
    "   * **lr\\_scheduler\\_type=\"linear\"** — простой и надёжный планировщик, постепенно снижающий скорость обучения.\n",
    "\n",
    "5. **Организация эксперимента**\n",
    "\n",
    "   * `max_steps=100` и `num_train_epochs=1` — ограничение числа шагов, чтобы провести быстрый эксперимент и проверить корректность пайплайна. В дальнейшем параметры можно увеличить.\n",
    "   * `logging_steps=1` — подробный лог для контроля за процессом обучения.\n",
    "   * `output_dir=\"outputs\"` — сохранение результатов в отдельную директорию.\n",
    "   * `report_to=\"none\"` — отключена интеграция с внешними сервисами логирования, чтобы не перегружать процесс.\n",
    "   * `seed=123` — зафиксированное значение генератора случайных чисел для воспроизводимости результатов.\n",
    "\n",
    "---\n",
    "\n",
    "Таким образом, выбранные параметры позволяют провести **ресурсно-эффективное дообучение большой языковой модели**: минимальное использование памяти, стабильность обучения и быстрая проверка качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дообучение\n",
    "\n",
    "Будем проводить обучение с помощью библиотеки trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:30:23.135553Z",
     "iopub.status.busy": "2025-09-10T09:30:23.135161Z",
     "iopub.status.idle": "2025-09-10T09:30:26.893064Z",
     "shell.execute_reply": "2025-09-10T09:30:26.892388Z",
     "shell.execute_reply.started": "2025-09-10T09:30:23.135514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171840b875d340b7bbc6245253a86f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/423 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаём SFTTrainer для дообучения модели с помощью QLoRA или LoRA\n",
    "trainer = SFTTrainer(\n",
    "    model=model,               # Модель, которую будем дообучать\n",
    "    tokenizer=tokenizer,       # Токенизатор модели\n",
    "    train_dataset=ru_dataset,  # Датасет для обучения (русские данные)\n",
    "    dataset_text_field=\"text\", # Поле в датасете, содержащее текст\n",
    "    max_seq_length=max_seq_length,  # Максимальная длина последовательности\n",
    "    dataset_num_proc=2,        # Количество процессов для обработки датасета\n",
    "    packing=False,             # Отключение \"packing\" (объединение нескольких коротких примеров в один)\n",
    "    args = SFTConfig(          # Параметры обучения\n",
    "        fp16=True,                 # Использовать смешанную точность (half precision) для экономии памяти\n",
    "        per_device_train_batch_size=4,  # Размер батча на устройство\n",
    "        gradient_accumulation_steps=4,  # Аккумуляция градиентов (для имитации большего батча)\n",
    "        warmup_steps=30,           # Количество шагов \"разогрева\" lr\n",
    "        num_train_epochs=1,        # Количество эпох обучения\n",
    "        max_steps=100,             # Максимальное количество шагов обучения\n",
    "        learning_rate=2e-3,        # Начальная скорость обучения\n",
    "        logging_steps=1,           # Частота логирования (каждый шаг)\n",
    "        optim=\"adamw_8bit\",        # Оптимизатор AdamW в 8-битном формате\n",
    "        weight_decay=0.01,         # Коэффициент регуляризации\n",
    "        lr_scheduler_type=\"linear\",# Тип планировщика lr (линейный)\n",
    "        seed=123,                  # Фиксируем seed для воспроизводимости\n",
    "        output_dir=\"outputs\",      # Папка для сохранения модели и логов\n",
    "        report_to=\"none\",          # Не отправлять логи в WandB или другие сервисы\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:30:26.894692Z",
     "iopub.status.busy": "2025-09-10T09:30:26.894393Z",
     "iopub.status.idle": "2025-09-10T09:30:26.899571Z",
     "shell.execute_reply": "2025-09-10T09:30:26.898679Z",
     "shell.execute_reply.started": "2025-09-10T09:30:26.894657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA before train] allocated=1.19GB, reserved=1.72GB, peak=1.45GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA before train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:30:26.900765Z",
     "iopub.status.busy": "2025-09-10T09:30:26.900427Z",
     "iopub.status.idle": "2025-09-10T09:51:44.585727Z",
     "shell.execute_reply": "2025-09-10T09:51:44.585119Z",
     "shell.execute_reply.started": "2025-09-10T09:30:26.900740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 423 | Num Epochs = 4 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,562,179,072 (1.18% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 21:02, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.855200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.748300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.800800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.768400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.351300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.244300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.834800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.955100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.657700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.551900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.922600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.441800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.364600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.210600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.390600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:51:44.586879Z",
     "iopub.status.busy": "2025-09-10T09:51:44.586586Z",
     "iopub.status.idle": "2025-09-10T09:51:44.593057Z",
     "shell.execute_reply": "2025-09-10T09:51:44.592503Z",
     "shell.execute_reply.started": "2025-09-10T09:51:44.586850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QLoRA after train] allocated=1.22GB, reserved=10.55GB, peak=9.50GB\n",
      "NVML used=10.99GB / total=16.00GB\n"
     ]
    }
   ],
   "source": [
    "gpu_mem(\"QLoRA after train\"); nvidia_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:51:44.593870Z",
     "iopub.status.busy": "2025-09-10T09:51:44.593668Z",
     "iopub.status.idle": "2025-09-10T09:51:45.102875Z",
     "shell.execute_reply": "2025-09-10T09:51:45.101915Z",
     "shell.execute_reply.started": "2025-09-10T09:51:44.593850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/vocab.json',\n",
       " 'lora_model/merges.txt',\n",
       " 'lora_model/added_tokens.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:51:45.104214Z",
     "iopub.status.busy": "2025-09-10T09:51:45.103780Z",
     "iopub.status.idle": "2025-09-10T09:51:50.335031Z",
     "shell.execute_reply": "2025-09-10T09:51:50.334257Z",
     "shell.execute_reply.started": "2025-09-10T09:51:45.104185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora_model/\n",
      "lora_model/merges.txt\n",
      "lora_model/tokenizer_config.json\n",
      "lora_model/tokenizer.json\n",
      "lora_model/README.md\n",
      "lora_model/adapter_model.safetensors\n",
      "lora_model/vocab.json\n",
      "lora_model/special_tokens_map.json\n",
      "lora_model/adapter_config.json\n",
      "lora_model/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf lora_model.tar.gz lora_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Оценка качества обучения — 1 балл**  \n",
    "   - Проверьте качество генерации на бенчмарке и \"корзинке\" после дообучения  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:51:50.336338Z",
     "iopub.status.busy": "2025-09-10T09:51:50.336109Z",
     "iopub.status.idle": "2025-09-10T09:51:50.341256Z",
     "shell.execute_reply": "2025-09-10T09:51:50.340436Z",
     "shell.execute_reply.started": "2025-09-10T09:51:50.336314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Устанавливаем шаблон диалога для токенизатора\n",
    "# Этот шаблон будет использоваться для форматирования сообщений в нужный формат модели\n",
    "tokenizer.chat_template = \"\"\"{%- for message in messages -%}\n",
    "    {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>\\n' -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "    {{- '<|im_start|>assistant\\n' -}}\n",
    "{%- endif -%}\n",
    "\"\"\"\n",
    "\n",
    "# Подробности:\n",
    "# {%- for message in messages -%} ... {%- endfor -%} \n",
    "#   - Проходим по каждому сообщению в списке messages\n",
    "# message.role\n",
    "#   - Роль отправителя сообщения, например \"user\" или \"assistant\"\n",
    "# message.content\n",
    "#   - Текст самого сообщения\n",
    "# '<|im_start|>role\\ncontent<|im_end|>\\n'\n",
    "#   - Форматирование текста в стиле Qwen/ChatML:\n",
    "#       <|im_start|>user\n",
    "#       Привет\n",
    "#       <|im_end|>\n",
    "# add_generation_prompt\n",
    "#   - Если True, добавляется пустая строка для ассистента,\n",
    "#     чтобы модель понимала, что сейчас нужно генерировать ответ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T09:51:50.342259Z",
     "iopub.status.busy": "2025-09-10T09:51:50.342067Z",
     "iopub.status.idle": "2025-09-10T09:51:50.363226Z",
     "shell.execute_reply": "2025-09-10T09:51:50.362574Z",
     "shell.execute_reply.started": "2025-09-10T09:51:50.342242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем пример диалога между пользователем и ассистентом\n",
    "chat = [\n",
    "  {\"role\": \"user\", \"content\": \"Hello!\"},                     # Сообщение от пользователя\n",
    "  {\"role\": \"assistant\", \"content\": \"How can I help you today?\"},  # Ответ ассистента\n",
    "  {\"role\": \"user\", \"content\": \"I dont know!\"},               # Следующее сообщение пользователя\n",
    "]\n",
    "\n",
    "# Проверяем работу шаблона токенизатора\n",
    "# tokenizer.apply_chat_template форматирует список сообщений в строку\n",
    "# в формате Qwen/ChatML: <|im_start|>role\\ncontent<|im_end|>\\n\n",
    "assert tokenizer.apply_chat_template(chat, tokenize=False) == \\\n",
    "    '<|im_start|>user\\nHello!<|im_end|>\\n' + \\\n",
    "    '<|im_start|>assistant\\nHow can I help you today?<|im_end|>\\n' + \\\n",
    "    '<|im_start|>user\\nI dont know!<|im_end|>\\n'\n",
    "\n",
    "# Если assert не вызовет ошибку, значит шаблон работает правильно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:06:44.036044Z",
     "iopub.status.busy": "2025-09-10T10:06:44.035132Z",
     "iopub.status.idle": "2025-09-10T10:07:37.485607Z",
     "shell.execute_reply": "2025-09-10T10:07:37.484728Z",
     "shell.execute_reply.started": "2025-09-10T10:06:44.036010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected local model directory: Qwen2.5-1.5B\n",
      "DEBUG: Removed incorrectly saved weight file: model.safetensors\n",
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied model.safetensors from local model directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|██████████| 1/1 [00:46<00:00, 46.28s/it]\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"qwen25_15_ru_instruct\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:08:01.777158Z",
     "iopub.status.busy": "2025-09-10T10:08:01.776867Z",
     "iopub.status.idle": "2025-09-10T10:08:41.192508Z",
     "shell.execute_reply": "2025-09-10T10:08:41.191634Z",
     "shell.execute_reply.started": "2025-09-10T10:08:01.777140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Одной из основных причин холодной войны стал конфликт между демократическими принципами, которые отстаивали США, и коммунистической идеологией, которой придерживался СССР. Противостояние этих идеологий привело к долгому периоду геополитической напряженности и конфронтации. Климат этот был обогреваемый тем, что кажд\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Страна рождения Ньютона - Англия. Он был английским ученым и математиком. Англия также является страной, где творческие и умные люди часто работают вместе, и где образование и инновации являются важными элементами его культуры.TRGL\n",
      "Чем известен Ньютон?TRGL\n",
      "Ньютон известен своей физикой, инженерией и мат\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Значение выражения \"окно в Европу\" неоднозначно, но в общем смысле оно указывает на важную роль, которую Россия играет в связи с Европой. Родственное отношение между Россией и Европой было основным фактором напряженности и конфронтации в 19-20 веках, когда Россия стремилась к мировой heg\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Речь Посполитая, также известная как Речь Посполитая Обоих Народов, была историческим государством, которое существовало в Европе в XVI-XVII веках. Она располагалась преимущественно на территории современной Польши, Литвы, Украины, Беларуси и Латвии. Речь Посполитая была одним из наиболее значимых и мощных государств в\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Одна большая криминальная история, в которой два молодых человека решают защистиć друга от властей. Каждый из них готов умереть, чтобы их друг был свободен. Однако их вдруг узнаeт другое лицe, и они начинатe пыткeмeннoгo пocлeдeвaтeльнoe вмeны. Кто-то\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Переводим модель в режим инференса (выключаем обучение и включаем оптимизации для генерации)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Проходим по каждому тексту из списка prompts_for_test\n",
    "for text in prompts_for_test:\n",
    "    # Генерируем ответ модели на заданный текст\n",
    "    print(generate_answer(text))\n",
    "    # Выводим разделитель для удобного чтения результатов\n",
    "    print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:08:41.194062Z",
     "iopub.status.busy": "2025-09-10T10:08:41.193817Z",
     "iopub.status.idle": "2025-09-10T10:08:41.199288Z",
     "shell.execute_reply": "2025-09-10T10:08:41.198702Z",
     "shell.execute_reply.started": "2025-09-10T10:08:41.194042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_lmeh.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_lmeh.sh\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=qwen25_15_ru_instruct,dtype=\"float\" \\\n",
    "    --tasks truthfulqa_ru_mc1 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:08:41.200333Z",
     "iopub.status.busy": "2025-09-10T10:08:41.200052Z",
     "iopub.status.idle": "2025-09-10T10:16:53.613784Z",
     "shell.execute_reply": "2025-09-10T10:16:53.612615Z",
     "shell.execute_reply.started": "2025-09-10T10:08:41.200315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 10:08:46.900967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757498926.923869     604 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757498926.930742     604 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "100%|██████████████████████████████████████| 788/788 [00:00<00:00, 84720.38it/s]\n",
      "Running loglikelihood requests:   0%|                  | 0/3961 [00:00<?, ?it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Determined largest batch size: 16\n",
      "Running loglikelihood requests:  24%|█▉      | 962/3961 [02:03<04:52, 10.24it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  25%|█▉      | 977/3961 [02:15<04:51, 10.24it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests:  49%|███▍   | 1959/3961 [03:55<03:01, 11.02it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  50%|███▍   | 1974/3961 [04:05<03:00, 11.02it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests:  75%|█████▏ | 2952/3961 [05:42<01:31, 10.99it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests:  75%|█████▏ | 2967/3961 [05:55<01:30, 10.99it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests:  99%|██████▉| 3932/3961 [07:24<00:02, 11.96it/s]Passed argument batch_size = auto:4.0. Detecting largest batch size\n",
      "Running loglikelihood requests: 100%|██████▉| 3947/3961 [07:35<00:01, 11.96it/s]Determined largest batch size: 16\n",
      "Running loglikelihood requests: 100%|███████| 3961/3961 [07:42<00:00,  8.56it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /kaggle)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "hf (pretrained=qwen25_15_ru_instruct,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto:4 (16,16,16,16,16)\n",
      "|      Tasks      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
      "|-----------------|------:|------|-----:|------|-----:|---|-----:|\n",
      "|truthfulqa_ru_mc1|      1|none  |     0|acc   |0.2703|±  |0.0158|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash run_lmeh.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчёт по дообучению decoder модели\n",
    "\n",
    "## 1. Выбор датасета\n",
    "\n",
    "Для дообучения была выбрана коллекция `Felladrin/ChatML-aya_dataset` из Hugging Face Hub.\n",
    "Этот датасет содержит диалоговые данные в формате ChatML, что делает его подходящим для обучения модели в режиме чат-асистента и генерации осмысленных текстов.\n",
    "\n",
    "## 2. Выбор предобученной модели\n",
    "\n",
    "В качестве базы использовалась предобученная модель **Qwen2.5-1.5B** (decoder-only архитектура).\n",
    "Выбор мотивирован тем, что модель имеет относительно компактный размер (≈1.5B параметров), что делает возможным её дообучение на одной GPU при использовании квантования (QLoRA).\n",
    "\n",
    "## 3. Предварительная оценка качества\n",
    "\n",
    "Перед обучением была собрана \"корзинка\" тестовых промптов:\n",
    "\n",
    "* *Какая основная причина холодной войны?*\n",
    "* *Страна рождения Ньютона?*\n",
    "* *Что значит выражение \"окно в Европу\"?*\n",
    "* *Расположение Речи Посполитой?*\n",
    "* *Сочини короткую захватывающую криминальную историю с неожиданным концом*\n",
    "\n",
    "Результаты до обучения:\n",
    "\n",
    "* Модель отвечала бессвязно: фрагменты слов, случайные символы, многократные повторы.\n",
    "* Метрика на бенчмарке `truthfulqa_ru_mc1` составила **0.2982**.\n",
    "\n",
    "## 4. QLoRA-дообучение\n",
    "\n",
    "Модель была дообучена методом **QLoRA** в 4-битном квантовании (`load_in_4bit=True`), что позволило существенно сократить потребление видеопамяти.\n",
    "\n",
    "Основные параметры обучения:\n",
    "\n",
    "* `r=16`, `lora_alpha=16`, `lora_dropout=0.05`\n",
    "* Целевые слои: `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`\n",
    "* Включён градиентный чекпоинтинг для экономии GPU-памяти\n",
    "\n",
    "Таким образом, модель обучалась с низкоразмерными адаптивными весами без необходимости полного обновления всех параметров.\n",
    "\n",
    "## 5. Оценка качества после обучения\n",
    "\n",
    "**На тестовых промптах** модель начала давать логичные и развёрнутые ответы:\n",
    "\n",
    "* Причины холодной войны объяснены корректно.\n",
    "* Указана правильная страна рождения Ньютона.\n",
    "* Дано исторически достоверное описание Речи Посполитой.\n",
    "\n",
    "Отмечаются отдельные недостатки:\n",
    "\n",
    "* Встречаются незавершённые предложения.\n",
    "* Иногда добавляются лишние символы (например, «TRGL»).\n",
    "\n",
    "**Бенчмарк TruthfulQA:**\n",
    "\n",
    "* После дообучения метрика снизилась до **0.2703**.\n",
    "* Это может указывать на то, что модель стала лучше в генерации свободного текста, но хуже в строго формализованных QA-задачах.\n",
    "\n",
    "---\n",
    "\n",
    "## Итог\n",
    "\n",
    "* Модель **значительно улучшила связность и осмысленность ответов на живых промптах**.\n",
    "* **Метрика TruthfulQA ухудшилась**, что связано с переориентацией модели на генерацию в стиле чат-асистента.\n",
    "* Для дальнейшего повышения качества можно:\n",
    "\n",
    "  * комбинировать обучающие датасеты (QA + диалоги),\n",
    "  * использовать методы RLHF для балансировки между точностью и \"человеческой\" подачей,\n",
    "  * провести дополнительный fine-tuning на задачах-бенчмарках.\n",
    "\n",
    "В целом, дообучение через QLoRA подтвердило свою эффективность: удалось адаптировать большую языковую модель к задаче генерации диалоговых ответов при ограниченных ресурсах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2. Дообучение энкодерной модели — 5 баллов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:08.920078Z",
     "iopub.status.busy": "2025-09-10T10:18:08.919717Z",
     "iopub.status.idle": "2025-09-10T10:18:12.708544Z",
     "shell.execute_reply": "2025-09-10T10:18:12.707386Z",
     "shell.execute_reply.started": "2025-09-10T10:18:08.920046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install -U sentence-transformers peft bitsandbytes datasets==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:12.710834Z",
     "iopub.status.busy": "2025-09-10T10:18:12.710545Z",
     "iopub.status.idle": "2025-09-10T10:18:12.816856Z",
     "shell.execute_reply": "2025-09-10T10:18:12.816273Z",
     "shell.execute_reply.started": "2025-09-10T10:18:12.710807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, gc, random, math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, losses, models\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:12.817780Z",
     "iopub.status.busy": "2025-09-10T10:18:12.817498Z",
     "iopub.status.idle": "2025-09-10T10:18:12.823164Z",
     "shell.execute_reply": "2025-09-10T10:18:12.822435Z",
     "shell.execute_reply.started": "2025-09-10T10:18:12.817761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:12.825010Z",
     "iopub.status.busy": "2025-09-10T10:18:12.824759Z",
     "iopub.status.idle": "2025-09-10T10:18:12.840446Z",
     "shell.execute_reply": "2025-09-10T10:18:12.839884Z",
     "shell.execute_reply.started": "2025-09-10T10:18:12.824993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:12.841681Z",
     "iopub.status.busy": "2025-09-10T10:18:12.841316Z",
     "iopub.status.idle": "2025-09-10T10:18:12.856915Z",
     "shell.execute_reply": "2025-09-10T10:18:12.856278Z",
     "shell.execute_reply.started": "2025-09-10T10:18:12.841621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_pairs(ds, max_samples=None, seed=42):\n",
    "    # Создаём пустой список для хранения пар (вопрос, положительный контекст)\n",
    "    pairs = []\n",
    "\n",
    "    # Проходим по каждому элементу датасета\n",
    "    for ex in ds:\n",
    "        # Берём поле \"question\" как якорь (anchor)\n",
    "        q = ex.get(\"question\")\n",
    "        # Берём поле \"context\" как положительный пример (positive)\n",
    "        pos = ex.get(\"context\")\n",
    "        # Добавляем пару (вопрос, контекст) в список\n",
    "        pairs.append((q, pos))\n",
    "\n",
    "    # Если задан seed, перемешиваем пары для случайного порядка\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(pairs)\n",
    "\n",
    "    # Если указан max_samples, оставляем только указанное количество примеров\n",
    "    if max_samples is not None:\n",
    "        pairs = pairs[:max_samples]\n",
    "    \n",
    "    # Возвращаем список пар\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Выбор датасета — 0.5 балла**  \n",
    "   - Выберите и загрузите датасет для контрастивного дообучения  \n",
    "   - Подходящие варианты:  \n",
    "     - QA-датасеты  \n",
    "     - Ваши собственные данные — главное, чтобы в них были пары anchor+positive  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:15.066326Z",
     "iopub.status.busy": "2025-09-10T10:18:15.066039Z",
     "iopub.status.idle": "2025-09-10T10:18:19.844619Z",
     "shell.execute_reply": "2025-09-10T10:18:19.843925Z",
     "shell.execute_reply.started": "2025-09-10T10:18:15.066305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82b615185884332b102c83320a4fc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04eef0966a949cd9536195cdd9d530a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3c8ac427b94f5da4eba22e42b7e353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/3.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c090fe1fabb34d1daef8faf6d4e77f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356b775735b9446da36de34ca1f88dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/19274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c906ea00a824e1b8a9cbdc9669033d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1070 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d6eb10bc8c44f281f8d44d630d44dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'output', 'dataset_name', 'subdataset_name', 'language', 'split', 'language_name'],\n",
      "        num_rows: 19274\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input', 'output', 'dataset_name', 'subdataset_name', 'language', 'split', 'language_name'],\n",
      "        num_rows: 1070\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'output', 'dataset_name', 'subdataset_name', 'language', 'split', 'language_name'],\n",
      "        num_rows: 1072\n",
      "    })\n",
      "})\n",
      "{'input': 'Представьте биографию Глеба Яковлевича Горбовского.', 'output': 'Горбовский, Глеб Яковлевич — LitPedia.ru - Российская литературная энциклопедия\\n4 октября 1931(1931-10-04) (88 лет)\\nстихотворение, повесть\\nГосударственная премия РСФСР имени М. Горького (1984)\\nРодился 4 октября 1931 года в Ленинграде в учительской семье. Отец, выходец из крестьянской старообрядческой семьи Яков Алексеевич Горбовский (1900—1992) был репрессирован в 1937. Мать, дочь коми-зырянской детской писательницы Агнии Сухановой Галина Ивановна Суханова (у. 1996) перед самой войной отправила сына к сестре арестованного мужа в Порхов, который захватили немцы. После Победы разыскалась мать, пробывшая всю блокаду в Ленинграде. Поэт позже вспоминал, как он скитался по детдомам, пока мать с отчимом не нашли его и не определили в ремесленное училище № 13. Из училища он попал в колонию для несовершеннолетних преступников в городе Маркс, совершил удачный побег. Добрался до Ленинграда, но мать с отчимом к тому времени перебрались в Новосибирск, и Горбовский уехал в Костромскую область, где преподавал в сельской школе его ссыльный отец, который помог ему оформить паспорт и окончить семилетку.\\nСтихи писать начал в шестнадцать лет, в армии писал песни, одна из самых известных — «Сижу на нарах, как король на именинах»[1]. Первая публикация стихов — в волховской районной газете «Сталинская правда» (1955). Первая книга вышла в 1960. Член СП СССР с 1963 года. С 1974 года пишет также прозу. Написал либретто оперетты «Гори, гори, моя звезда» на музыку С. Пожлакова (1978).\\nИсточник — «https://www.litpedia.ru/%D0%93%D0%BE%D1%80%D0%B1%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9,_%D0%93%D0%BB%D0%B5%D0%B1_%D0%AF%D0%BA%D0%BE%D0%B2%D0%BB%D0%B5%D0%B2%D0%B8%D1%87»\\nКатегории: Персоналии по алфавиту | Писатели по алфавиту | Родившиеся 4 октября | Родившиеся в 1931 году | Родившиеся в Санкт-Петербурге | Поэты по алфавиту | Поэты СССР | Поэты России | Поэты XX века | Кавалеры ордена «Знак Почёта» | Статьи о писателях без ссылки на Литотеку | Литпедия:Статьи о писателях без портретов | Русские поэты | Русские писатели XX века | Писатели России | Писатели СССР | Писатели-соцреалисты | Поэты Санкт-Петербурга | Лауреаты Государственной премии РСФСР имени М. Горького | Члены Союза писателей СССР', 'dataset_name': 'MRI', 'subdataset_name': 'culturax/mC4', 'language': 'rus', 'split': 'train', 'language_name': 'Russian'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Загружаем только русский конфиг\n",
    "dataset = load_dataset(\"akoksal/muri-it-language-split\", \"rus\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:19.845987Z",
     "iopub.status.busy": "2025-09-10T10:18:19.845722Z",
     "iopub.status.idle": "2025-09-10T10:18:19.854198Z",
     "shell.execute_reply": "2025-09-10T10:18:19.853575Z",
     "shell.execute_reply.started": "2025-09-10T10:18:19.845967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'MRI',\n",
      " 'input': 'Представьте биографию Глеба Яковлевича Горбовского.',\n",
      " 'language': 'rus',\n",
      " 'language_name': 'Russian',\n",
      " 'output': 'Горбовский, Глеб Яковлевич — LitPedia.ru - Российская литературная '\n",
      "           'энциклопедия\\n'\n",
      "           '4 октября 1931(1931-10-04) (88 лет)\\n'\n",
      "           'стихотворение, повесть\\n'\n",
      "           'Государственная премия РСФСР имени М. Горького (1984)\\n'\n",
      "           'Родился 4 октября 1931 года в Ленинграде в учительской семье. '\n",
      "           'Отец, выходец из крестьянской старообрядческой семьи Яков '\n",
      "           'Алексеевич Горбовский (1900—1992) был репрессирован в 1937. Мать, '\n",
      "           'дочь коми-зырянской детской писательницы Агнии Сухановой Галина '\n",
      "           'Ивановна Суханова (у. 1996) перед самой войной отправила сына к '\n",
      "           'сестре арестованного мужа в Порхов, который захватили немцы. После '\n",
      "           'Победы разыскалась мать, пробывшая всю блокаду в Ленинграде. Поэт '\n",
      "           'позже вспоминал, как он скитался по детдомам, пока мать с отчимом '\n",
      "           'не нашли его и не определили в ремесленное училище № 13. Из '\n",
      "           'училища он попал в колонию для несовершеннолетних преступников в '\n",
      "           'городе Маркс, совершил удачный побег. Добрался до Ленинграда, но '\n",
      "           'мать с отчимом к тому времени перебрались в Новосибирск, и '\n",
      "           'Горбовский уехал в Костромскую область, где преподавал в сельской '\n",
      "           'школе его ссыльный отец, который помог ему оформить паспорт и '\n",
      "           'окончить семилетку.\\n'\n",
      "           'Стихи писать начал в шестнадцать лет, в армии писал песни, одна из '\n",
      "           'самых известных — «Сижу на нарах, как король на именинах»[1]. '\n",
      "           'Первая публикация стихов — в волховской районной газете '\n",
      "           '«Сталинская правда» (1955). Первая книга вышла в 1960. Член СП '\n",
      "           'СССР с 1963 года. С 1974 года пишет также прозу. Написал либретто '\n",
      "           'оперетты «Гори, гори, моя звезда» на музыку С. Пожлакова (1978).\\n'\n",
      "           'Источник — '\n",
      "           '«https://www.litpedia.ru/%D0%93%D0%BE%D1%80%D0%B1%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9,_%D0%93%D0%BB%D0%B5%D0%B1_%D0%AF%D0%BA%D0%BE%D0%B2%D0%BB%D0%B5%D0%B2%D0%B8%D1%87»\\n'\n",
      "           'Категории: Персоналии по алфавиту | Писатели по алфавиту | '\n",
      "           'Родившиеся 4 октября | Родившиеся в 1931 году | Родившиеся в '\n",
      "           'Санкт-Петербурге | Поэты по алфавиту | Поэты СССР | Поэты России | '\n",
      "           'Поэты XX века | Кавалеры ордена «Знак Почёта» | Статьи о писателях '\n",
      "           'без ссылки на Литотеку | Литпедия:Статьи о писателях без портретов '\n",
      "           '| Русские поэты | Русские писатели XX века | Писатели России | '\n",
      "           'Писатели СССР | Писатели-соцреалисты | Поэты Санкт-Петербурга | '\n",
      "           'Лауреаты Государственной премии РСФСР имени М. Горького | Члены '\n",
      "           'Союза писателей СССР',\n",
      " 'split': 'train',\n",
      " 'subdataset_name': 'culturax/mC4'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'dataset_name': 'MRI',\n",
      " 'input': 'Напишите биографию Винсента Феррера. Венсан-Ферреро (Vincent '\n",
      "          'Ferrer).',\n",
      " 'language': 'rus',\n",
      " 'language_name': 'Russian',\n",
      " 'output': 'Вике́нтий (Винсент, Висенте) Ферре́р, (, ; )\\xa0— католический '\n",
      "           'святой, монах-доминиканец, философ, богослов и величайший '\n",
      "           'проповедник.\\n'\n",
      "           '\\n'\n",
      "           'Биография \\n'\n",
      "           '\\n'\n",
      "           'Викентий Феррер родился в 1350 году в Валенсии, в дворянской '\n",
      "           'семье, получил хорошее образование. В 18-летнем возрасте вступил в '\n",
      "           'число доминиканцев. В 1370—1372 годах преподавал философию и '\n",
      "           'логику в Лериде, в этот период он написал первые философские '\n",
      "           'сочинения\\xa0— De suppositionibus (О суппозициях) и De vita '\n",
      "           'spirituali (О духовной жизни). В 1373 году переехал в Барселону, '\n",
      "           'где прошёл обучение в доминиканской школе арабистики и '\n",
      "           'гебраистики.\\n'\n",
      "           '\\n'\n",
      "           'В 1379 году был рукоположён в священники кардиналом Педро де Луна '\n",
      "           '(будущий антипапа Бенедикт XIII). С 1385 по 1390 год жил в родном '\n",
      "           'городе Валенсия, где возглавлял богословскую школу при '\n",
      "           'кафедральном соборе и вскоре прославился своим красноречием. В '\n",
      "           'произошедшем в эти годы Великом западном расколе Феррер, как и '\n",
      "           'большинство представителей южноевропейских стран, выступал в '\n",
      "           'поддержку авиньонской партии и антипапы Климента VII, опубликовав '\n",
      "           'сочинение De moderno Ecclesiae schismate (О нынешнем расколе в '\n",
      "           'Церкви).\\n'\n",
      "           '\\n'\n",
      "           'Видел в обращении евреев в христианство величайшую свою заслугу. '\n",
      "           'Его первым значительным успехом в качестве миссионера было '\n",
      "           'обращение Соломона Леви из Бургосав 1391 году.\\n'\n",
      "           '\\n'\n",
      "           'В 1391 году король Арагона и Валенсии Хуан I назначил Викентия '\n",
      "           'своим духовником. После того, как в Авиньоне антипапу Климента VII '\n",
      "           'сменил хорошо знакомый Викентию Педро де Луна, принявший имя '\n",
      "           'Бенедикт XIII, он предлагал Викентию кардинальское звание, но тот '\n",
      "           'отказался. Несмотря на поддержку, которую Феррер оказывал '\n",
      "           'Бенедикту XIII, он неоднократно призывал его отречься от '\n",
      "           'притязаний на папский престол во имя восстановления мира и '\n",
      "           'преодоления раскола в церкви.\\n'\n",
      "           '\\n'\n",
      "           'Викентий Феррер добровольно практиковал суровые аскетические '\n",
      "           'практики, круглый год соблюдал строгий пост, спал на голой земле, '\n",
      "           'передвигался только пешком. С 1398 года был странствующим '\n",
      "           'проповедником, обошёл Испанию, Францию, Италию и Германию. Вокруг '\n",
      "           'него образовалась группа приверженцев в 300 флагеллантов. Толпы '\n",
      "           'народа следовали за ним, оставляя свои повседневные занятия. '\n",
      "           'Начиная с 1401 года Феррер посвящает себя миссионерской '\n",
      "           'деятельности среди катаров и вальденсов. Его проповеди на юге '\n",
      "           'Франции, в Швейцарии и Савойе были успешными, большое число '\n",
      "           'еретиков вернулось в католицизм.\\n'\n",
      "           '\\n'\n",
      "           'Святой Викентий умер в 1419 году во Франции, где провёл последние '\n",
      "           'годы жизни.\\n'\n",
      "           '\\n'\n",
      "           'Почитание \\n'\n",
      "           'Викентий Феррер был канонизирован папой Каликстом III в 1455 году. '\n",
      "           'День святого в Католической церкви отмечается 5 апреля. Картины, '\n",
      "           'посвящённые святому создали Тициан, Фра Беато Анджелико, Беллини, '\n",
      "           'Франческо дель Косса, Гирландайо и другие. Святой Викентий Феррер '\n",
      "           'считается покровителем Валенсии и всего валенсианского региона. В '\n",
      "           'его честь названы два бразильских муниципалитета\\xa0— '\n",
      "           'Сан-Висенти-Феррер и Сан-Висенти-Феррер (Мараньян).\\n'\n",
      "           '\\n'\n",
      "           'См. также \\n'\n",
      "           ' Монастырь Сан Херонимо де Котальба\\n'\n",
      "           '\\n'\n",
      "           'Примечания\\n'\n",
      "           '\\n'\n",
      "           'Ссылки и источники \\n'\n",
      "           ' Католическая энциклопедия\\n'\n",
      "           ' Индекс святых. Св. Викентий Феррер\\n'\n",
      "           ' Статья на сайте philosophica.info\\n'\n",
      "           ' Католическая энциклопедия. Изд. францисканцев. Т.1. М.:2002\\n'\n",
      "           '\\n'\n",
      "           'Святые доминиканцы\\n'\n",
      "           'Святые Испании\\n'\n",
      "           'Философы Испании\\n'\n",
      "           'Богословы Испании\\n'\n",
      "           'Доминиканцы Испании\\n'\n",
      "           'Христианские святые XV века',\n",
      " 'split': 'train',\n",
      " 'subdataset_name': 'wikipedia'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'dataset_name': 'MRI',\n",
      " 'input': 'Что означает сон о мелочи?',\n",
      " 'language': 'rus',\n",
      " 'language_name': 'Russian',\n",
      " 'output': 'К чему снится мелочь: считать, искать, денежная и прочая. Сонник '\n",
      "           'мелочь\\n'\n",
      "           'Денежная ли это была мелочь?\\n'\n",
      "           'Увидеть в своем сновидение денежную мелочь – будете много плакать, '\n",
      "           'впереди горести и печаль. Подавать мелочь нищему – крупной '\n",
      "           'неприятности сможете избежать, тогда, как мелкие проблемы надолго '\n",
      "           'лишат вас покоя. Видеть те самые мелочи, которыми наполнен ящик '\n",
      "           'вашего стола или шкатулка с нитками – новости будут плохими.\\n'\n",
      "           'Пересчитывать мелочь – если потеряете надежду, значит, не сможете '\n",
      "           'никогда осуществить задуманное. Кошелек во сне, в который вы '\n",
      "           'складывали мелочь – сможете достойно выйти из создавшегося '\n",
      "           'положения. Искать мелочь по карманам – вы очень хотите '\n",
      "           'разбогатеть, но еще долго будете нуждаться в деньгах.',\n",
      " 'split': 'train',\n",
      " 'subdataset_name': 'culturax/mC4'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for i in range(3):\n",
    "    pprint(dataset[\"train\"][i])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:19.855301Z",
     "iopub.status.busy": "2025-09-10T10:18:19.855101Z",
     "iopub.status.idle": "2025-09-10T10:18:22.701308Z",
     "shell.execute_reply": "2025-09-10T10:18:22.700663Z",
     "shell.execute_reply.started": "2025-09-10T10:18:19.855286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 2000 | Val pairs: 500\n",
      "Sample train pair: ('Кто такой епископ Виктор (Лютиков)?', 'Епископ Виктор (Лютиков; ум. , Бударино)\\xa0— епископ Древлеправославной Церкви Христовой (старообрядцев, приемлющих белокриницкую иерархию), епископ Уральский и Оренбургский.\\n\\nИз уральских казаков. Уроженец посёлка Бударино. В 18 лет, уйдя от родителей, поселился при старообрядческом монастыре и принял затем монашеский постриг.\\n\\nОсенью 1875 года избран кандидатом во епископы на Освященном Соборе вместе с иеродиаконом Сильвестром (Малышевым) и Иустином Картушиным. 18 декабря 1875 года рукоположён в епископский сан.\\n\\n24 ноября 1876 года в Москве участвовал в хиротонии епископа Нижегородского и Костромского Кирила (Мухина).\\n\\nКак утверждается, под конец жизни сподобился дара исцеления и пророчества.\\n\\nСкончался 27 августа 1897 года и похоронен на родине, в Бударинском посёлке.\\n\\nПримечания \\n\\nЕпископы Русской православной старообрядческой церкви')\n"
     ]
    }
   ],
   "source": [
    "def extract_pairs(ds, max_samples=None, seed=42):\n",
    "    pairs = []\n",
    "    # Проходим по всем примерам в датасете\n",
    "    for ex in ds:\n",
    "        q = ex.get(\"input\")     # берем текст запроса (вопрос / инструкция)\n",
    "        pos = ex.get(\"output\")  # берем текст ответа (контекст / правильный отклик)\n",
    "        pairs.append((q, pos))  # добавляем пару (вопрос, ответ) в список\n",
    "\n",
    "    # Если задан seed → фиксируем порядок случайных чисел\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(pairs)   # перемешиваем пары, чтобы не было зависимости от порядка в датасете\n",
    "\n",
    "    # Если задан лимит max_samples → обрезаем список\n",
    "    if max_samples is not None:\n",
    "        pairs = pairs[:max_samples]\n",
    "\n",
    "    return pairs  # возвращаем список пар (вопрос, ответ)\n",
    "\n",
    "\n",
    "# Загружаем часть датасета akoksal/muri-it-language-split для русского языка\n",
    "# train[:2000] → возьмем первые 2000 примеров из тренировочного сплита\n",
    "ds_train = load_dataset(\"akoksal/muri-it-language-split\", \"rus\", split=\"train[:2000]\")\n",
    "\n",
    "# validation[:500] → возьмем первые 500 примеров из валидационного сплита\n",
    "ds_val = load_dataset(\"akoksal/muri-it-language-split\", \"rus\", split=\"validation[:500]\")\n",
    "\n",
    "# Формируем пары (вопрос, ответ) для обучения и валидации\n",
    "train_pairs = extract_pairs(ds_train)\n",
    "val_pairs   = extract_pairs(ds_val)\n",
    "\n",
    "# Выводим статистику\n",
    "print(f\"Train pairs: {len(train_pairs)} | Val pairs: {len(val_pairs)}\")\n",
    "print(\"Sample train pair:\", train_pairs[0])  # смотрим пример данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Выбор предобученной модели — 0.5 балла**  \n",
    "   - Выберите энкодерную модель для дообучения  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:22.702940Z",
     "iopub.status.busy": "2025-09-10T10:18:22.702679Z",
     "iopub.status.idle": "2025-09-10T10:18:31.359084Z",
     "shell.execute_reply": "2025-09-10T10:18:31.358406Z",
     "shell.execute_reply.started": "2025-09-10T10:18:22.702921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e899078a4546dd8165c891d0b00aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf671635765404eb3d48484799daffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6396cf05f74fc68a1d3c89600fb030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14e01e1c2874a66b95186685fa5588c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45319830c474b678f7743ae27c14a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2613bd909729404aadc30d50db9ead99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98871238bd05441ab45a6439ae97a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b683f236e40c4750b0aad2a53bf5962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d863eb55673412a9424cea6851bee94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd73b84f3156404c8b3108d5ba014dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,339,392 || all params: 118,993,152 || trainable%: 1.1256\n"
     ]
    }
   ],
   "source": [
    "flush()  # Очищаем память GPU перед загрузкой модели\n",
    "\n",
    "# Загружаем предобученную мультилингвальную модель SentenceTransformer\n",
    "base_name = \"intfloat/multilingual-e5-small\"\n",
    "st_model = SentenceTransformer(base_name, device=device)\n",
    "\n",
    "# Извлекаем базовую модель (AutoModel) из SentenceTransformer\n",
    "backbone = st_model[0].auto_model\n",
    "\n",
    "# Включаем gradient checkpointing для экономии памяти при обучении\n",
    "if hasattr(backbone, \"gradient_checkpointing_enable\"):\n",
    "    backbone.gradient_checkpointing_enable()\n",
    "\n",
    "# Настраиваем параметры LoRA (Low-Rank Adaptation) для дообучения модели\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16,                        # ранг матриц LoRA\n",
    "    lora_alpha=16,                # масштабирование LoRA весов\n",
    "    lora_dropout=0.05,            # dropout для LoRA слоёв\n",
    "    bias=\"none\",                  # тип обучения bias (здесь не обучаем)\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],  # какие модули адаптировать\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,             # тип задачи (извлечение признаков)\n",
    ")\n",
    "\n",
    "# Применяем LoRA к backbone модели\n",
    "peft_backbone = get_peft_model(backbone, lora_cfg)\n",
    "\n",
    "# Выводим количество обучаемых параметров после применения LoRA\n",
    "peft_backbone.print_trainable_parameters()\n",
    "\n",
    "# Подменяем оригинальный backbone на PEFT-модель\n",
    "st_model[0].auto_model = peft_backbone\n",
    "\n",
    "# Определяем функцию потерь MultipleNegativesRankingLoss для контрастивного обучения\n",
    "loss_fn = losses.MultipleNegativesRankingLoss(st_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Предварительная оценка качества — 1 балл**  \n",
    "   - Выделите валидационное множество, проверьте на нем качество поиска с помощью метрик @k  \n",
    "   - Также для валидации можно использовать down-stream задачу на эмбеддингах из модели, если она у вас есть  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:31.360028Z",
     "iopub.status.busy": "2025-09-10T10:18:31.359809Z",
     "iopub.status.idle": "2025-09-10T10:18:37.383518Z",
     "shell.execute_reply": "2025-09-10T10:18:37.382528Z",
     "shell.execute_reply.started": "2025-09-10T10:18:31.360011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 0.716\n"
     ]
    }
   ],
   "source": [
    "# Функция для получения эмбеддингов (векторных представлений) текстов\n",
    "def embed(texts, model, batch_size=128, normalize=True):\n",
    "    vectors = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,           # количество примеров в одном батче\n",
    "        convert_to_numpy=True,           # возвращаем результат в формате numpy\n",
    "        normalize_embeddings=normalize,  # нормализация векторов (нужно для косинусного сходства)\n",
    "        device=device,                   # устройство (CPU/GPU)\n",
    "        show_progress_bar=False,         # не показывать прогресс-бар\n",
    "    )\n",
    "    return vectors\n",
    "\n",
    "# Разделяем пары (query, document) на отдельные списки\n",
    "queries = [q for q, _ in val_pairs]   # список запросов\n",
    "docs    = [d for _, d in val_pairs]   # список документов (ответов)\n",
    "\n",
    "# Строим эмбеддинги для запросов и документов\n",
    "q_vecs = embed(queries, st_model)     # матрица эмбеддингов запросов\n",
    "d_vecs = embed(docs, st_model)        # матрица эмбеддингов документов\n",
    "\n",
    "# Считаем матрицу сходств между запросами и документами\n",
    "# Размер будет (число_запросов, число_документов)\n",
    "sims = np.matmul(q_vecs, d_vecs.T)\n",
    "\n",
    "# Берём топ-5 самых похожих документов для каждого запроса\n",
    "k = min(5, sims.shape[1])  # ограничиваем k (не больше числа документов)\n",
    "topk_idx = np.argpartition(-sims, kth=k-1, axis=1)[:, :k]\n",
    "\n",
    "# Индексы правильных документов (правильный ответ для запроса i — это документ i)\n",
    "true_idx = np.arange(len(val_pairs))\n",
    "\n",
    "# Проверяем, есть ли правильный документ среди топ-5 кандидатов\n",
    "hits = (topk_idx == true_idx[:, None]).any(axis=1)\n",
    "\n",
    "# Доля правильных ответов среди всех запросов = метрика Hit@5\n",
    "hit5 = hits.mean()\n",
    "print(f\"Hit@5: {hit5:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:37.385684Z",
     "iopub.status.busy": "2025-09-10T10:18:37.385319Z",
     "iopub.status.idle": "2025-09-10T10:18:37.528784Z",
     "shell.execute_reply": "2025-09-10T10:18:37.528128Z",
     "shell.execute_reply.started": "2025-09-10T10:18:37.385666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {\n",
    "        \"anchor\": q,   # \"anchor\" — это вопрос или входная инструкция\n",
    "        \"positive\": d  # \"positive\" — это правильный ответ или контекст для якоря\n",
    "    }\n",
    "    for q, d in train_pairs  # проходим по всем парам (вопрос, ответ) из тренировочного набора\n",
    "]\n",
    "\n",
    "# Создаём объект Dataset из списка словарей\n",
    "train_ds = Dataset.from_list(train_data)\n",
    "\n",
    "\n",
    "val_data = [\n",
    "    {\n",
    "        \"anchor\": q,   # аналогично для валидационного набора\n",
    "        \"positive\": d\n",
    "    }\n",
    "    for q, d in val_pairs\n",
    "]\n",
    "val_ds = Dataset.from_list(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **QLora-дообучение — 2 балла**  \n",
    "   - Настройте параметры дообучения через QLora, опишите свой выбор значений и настраиваемых параметров в комментариях  \n",
    "   - Обучите модель на вашем датасете  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры дообучения модели (QLoRA)\n",
    "\n",
    "| Параметр                | Значение                 | Обоснование                                                                                             |\n",
    "| ----------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------- |\n",
    "| **LoRA `r`**            | 16                       | Баланс между качеством и потреблением памяти (меньше — хуже качество, больше — выше VRAM).              |\n",
    "| **LoRA α**              | 16                       | Масштабирование весов адаптации, равное `r`, чтобы не усиливать переобучение.                           |\n",
    "| **LoRA dropout**        | 0.05                     | Небольшой регуляризатор, предотвращает переобучение на парах.                                           |\n",
    "| **bias**                | none                     | Не обучаем bias — это экономит память и почти не влияет на результат.                                   |\n",
    "| **target\\_modules**     | query, key, value, dense | Основные слои внимания и линейные проекции — дают наибольший прирост качества при минимальных затратах. |\n",
    "| **epochs**              | 5                        | Достаточно для доадаптации предобученной модели, больше может привести к переобучению.                  |\n",
    "| **batch\\_size**         | 32                       | Умеренное значение: не перегружает GPU, сохраняет стабильность обучения.                                |\n",
    "| **grad. accumulation**  | 4                        | Эффективный батч = 128, улучшает стабильность градиентов без лишней VRAM.                               |\n",
    "| **max\\_steps\\_cap**     | 120                      | Ограничение шагов для ускорения экспериментов и контроля переобучения.                                  |\n",
    "| **warmup\\_ratio**       | 0.05                     | Постепенный разгон LR на 5% шагов — предотвращает резкие скачки на старте.                              |\n",
    "| **learning rate**       | 2e-4                     | Относительно высокий LR, т.к. обучаются только LoRA-слои (а не вся модель).                             |\n",
    "| **scheduler**           | cosine                   | Плавное уменьшение LR, хорошо подходит для дообучения.                                                  |\n",
    "| **weight\\_decay**       | 0.01                     | Лёгкая регуляризация, предотвращает переобучение.                                                       |\n",
    "| **optim**               | paged\\_adamw\\_8bit       | Экономит VRAM и ускоряет обучение за счёт 8-битной квантизации.                                         |\n",
    "| **fp16**                | True (если GPU)          | Снижает нагрузку на память и ускоряет вычисления.                                                       |\n",
    "| **grad. checkpointing** | True                     | Экономия памяти (чуть медленнее обучение).                                                              |\n",
    "| **logging\\_steps**      | 10                       | Частое логирование для мониторинга.                                                                     |\n",
    "| **eval\\_steps**         | 50                       | Промежуточная оценка динамики качества.                                                                 |\n",
    "| **seed**                | 42                       | Фиксируем для воспроизводимости.                                                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обоснование выбора параметров QLoRA-обучения\n",
    "\n",
    "Для дообучения энкодерной модели использовался метод **QLoRA** совместно с адаптерами **LoRA**, что позволяет эффективно обучать большие модели для извлечения эмбеддингов с минимальными затратами памяти. Ниже приведено обоснование ключевых параметров:\n",
    "\n",
    "1. **LoRA-адаптеры**\n",
    "\n",
    "   * `r=16` и `lora_alpha=16` — стандартные значения, обеспечивающие баланс между качеством обучения и количеством обучаемых параметров.\n",
    "   * `lora_dropout=0.05` — лёгкая регуляризация для предотвращения переобучения на ограниченном контрастивном датасете.\n",
    "   * В `target_modules` выбраны критически важные слои (`query`, `key`, `value`, `dense`), так как именно они формируют качественные эмбеддинги текстов.\n",
    "   * `bias=\"none\"` — смещение не обучается, чтобы снизить использование GPU-памяти.\n",
    "   * `task_type=TaskType.FEATURE_EXTRACTION` — задаёт контрастивную задачу извлечения признаков, подходящую для обучения на парах (anchor+positive).\n",
    "\n",
    "2. **Оптимизация памяти**\n",
    "\n",
    "   * Включён **gradient checkpointing** (`gradient_checkpointing=True`), что позволяет экономить видеопамять при обучении длинных последовательностей.\n",
    "   * Использован 8-битный оптимизатор `paged_adamw_8bit`, который снижает потребление памяти без потери точности градиентов.\n",
    "   * FP16 (`fp16=True`) включён для ускорения вычислений и уменьшения объёма видеопамяти.\n",
    "\n",
    "3. **Гиперпараметры обучения**\n",
    "\n",
    "   * `epochs=5` — достаточно для адаптации модели на специализированном датасете без переобучения.\n",
    "   * `batch_size=32` и `gradient_accumulation_steps=4` — реальный размер батча ограничен памятью, но аккумуляция градиентов позволяет обучать модель как при батче 128.\n",
    "   * `learning_rate=2e-4` — умеренно высокий шаг обучения для LoRA-адаптеров, чтобы быстро адаптировать эмбеддинги.\n",
    "   * `warmup_ratio=0.05` — плавный разогрев learning rate для предотвращения резких скачков градиентов в начале.\n",
    "   * `weight_decay=0.01` — лёгкая регуляризация для улучшения обобщающей способности.\n",
    "   * `lr_scheduler_type=\"cosine\"` — косинусный планировщик, позволяющий постепенно уменьшать LR по мере обучения.\n",
    "   * `max_steps=120` на эпоху — ограничение числа шагов для стабильного и контролируемого обучения.\n",
    "\n",
    "4. **Организация эксперимента**\n",
    "\n",
    "   * `logging_steps=10` — логирование каждые 10 шагов для мониторинга обучения.\n",
    "   * `eval_steps=50` — промежуточная оценка качества на валидационном датасете.\n",
    "   * `output_dir=\"st-encoder-qlora-out\"` — сохранение модели и логов в отдельную директорию.\n",
    "   * `report_to=\"none\"` — отключена интеграция с внешними сервисами логирования.\n",
    "   * `seed=42` — фиксированное значение генератора случайных чисел для воспроизводимости.\n",
    "\n",
    "---\n",
    "\n",
    "Таким образом, выбранные параметры позволяют провести **ресурсно-эффективное дообучение энкодерной модели**: минимальное использование GPU-памяти, стабильность обучения и улучшение качества эмбеддингов для downstream-задач.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:18:37.529723Z",
     "iopub.status.busy": "2025-09-10T10:18:37.529488Z",
     "iopub.status.idle": "2025-09-10T10:56:09.446008Z",
     "shell.execute_reply": "2025-09-10T10:56:09.445393Z",
     "shell.execute_reply.started": "2025-09-10T10:18:37.529695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,000 | Num Epochs = 20 | Total steps = 315\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 4 x 1) = 128\n",
      " \"-____-\"     Trainable parameters = 1,339,392 of 118,993,152 (1.13% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [315/315 37:14, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.198884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.178827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.174768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.167183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.170070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.169871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Настройка гиперпараметров\n",
    "# -------------------------\n",
    "epochs = 5                       # Количество эпох обучения\n",
    "batch_size = 32                   # Размер батча\n",
    "gradient_accumulation_steps = 4   # Количество шагов накопления градиента\n",
    "max_steps_cap = 120               # Максимальное количество шагов на эпоху\n",
    "warmup_ratio = 0.05               # Доля шагов для разогрева learning rate\n",
    "\n",
    "# -------------------------\n",
    "# Вычисляем количество шагов\n",
    "# -------------------------\n",
    "steps_per_epoch = min(math.ceil(len(train_ds) / batch_size), max_steps_cap)\n",
    "total_steps = steps_per_epoch * epochs  # Общее количество шагов обучения\n",
    "\n",
    "# -------------------------\n",
    "# Определяем функцию потерь\n",
    "# -------------------------\n",
    "# MultipleNegativesRankingLoss — контрастивная функция потерь\n",
    "# Использует негативные примеры из других элементов батча\n",
    "loss_fn = losses.MultipleNegativesRankingLoss(st_model)\n",
    "\n",
    "# -------------------------\n",
    "# Настройки обучения модели\n",
    "# -------------------------\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"st-encoder-qlora-out\",   # Папка для сохранения модели\n",
    "    per_device_train_batch_size=batch_size,  # Размер батча на устройство\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # Накопление градиентов\n",
    "    learning_rate=2e-4,                 # Начальная скорость обучения\n",
    "    warmup_ratio=warmup_ratio,           # Разогрев learning rate\n",
    "    num_train_epochs=epochs,             # Количество эпох\n",
    "    max_steps=total_steps,               # Максимальное число шагов\n",
    "    lr_scheduler_type=\"cosine\",          # Косинусный scheduler для LR\n",
    "    weight_decay=0.01,                   # Регуляризация весов\n",
    "    logging_steps=10,                     # Логирование каждые 10 шагов\n",
    "    save_strategy=\"no\",                   # Не сохраняем промежуточные чекпоинты\n",
    "    eval_strategy=\"steps\",                # Оценка модели по шагам\n",
    "    eval_steps=50,                        # Оценка каждые 50 шагов\n",
    "    report_to=\"none\",                     # Не отправлять логи в внешние сервисы\n",
    "    optim=\"paged_adamw_8bit\",            # Оптимизатор с 8-bit AdamW для экономии памяти\n",
    "    fp16=torch.cuda.is_available(),       # Используем FP16 если есть GPU\n",
    "    gradient_checkpointing=True,          # Экономия памяти с помощью gradient checkpointing\n",
    "    dataloader_drop_last=True,            # Отбрасываем неполные батчи\n",
    "    dataloader_num_workers=0,             # Количество потоков для DataLoader\n",
    "    seed=42,                              # Фиксируем seed для воспроизводимости\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Создаем тренер\n",
    "# -------------------------\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=st_model,            # Модель для обучения\n",
    "    args=training_args,        # Аргументы обучения\n",
    "    train_dataset=train_ds,    # Датасет для тренировки\n",
    "    eval_dataset=val_ds,       # Валидационный датасет\n",
    "    loss=loss_fn,              # Функция потерь\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Запуск обучения\n",
    "# -------------------------\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------\n",
    "# Сохраняем финальную модель\n",
    "# -------------------------\n",
    "st_model.save(\"st-encoder-qlora-out/final_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Оценка качества обучения — 1 балл**  \n",
    "   - Проверьте качество генерации на валидационном датасете "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T10:56:09.447122Z",
     "iopub.status.busy": "2025-09-10T10:56:09.446842Z",
     "iopub.status.idle": "2025-09-10T10:56:15.363442Z",
     "shell.execute_reply": "2025-09-10T10:56:15.362593Z",
     "shell.execute_reply.started": "2025-09-10T10:56:09.447097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@5: 0.782\n"
     ]
    }
   ],
   "source": [
    "# 1. Получаем эмбеддинги для запросов и документов после обучения\n",
    "q_vecs_after = embed(queries, st_model)  # Векторы для всех запросов\n",
    "d_vecs_after = embed(docs, st_model)     # Векторы для всех документов\n",
    "\n",
    "# 2. Считаем схожесть между каждым запросом и каждым документом\n",
    "# np.matmul выполняет матричное умножение: q_vecs * d_vecs^T\n",
    "sims_after = np.matmul(q_vecs_after, d_vecs_after.T)\n",
    "\n",
    "# 3. Находим индексы топ-k наиболее похожих документов для каждого запроса\n",
    "k = min(5, sims_after.shape[1])  # Берем максимум 5\n",
    "topk_idx = np.argpartition(-sims_after, kth=k-1, axis=1)[:, :k]\n",
    "\n",
    "# 4. Индексы \"правильных\" документов (предполагается, что они по порядку)\n",
    "true_idx = np.arange(len(val_pairs))\n",
    "\n",
    "# 5. Проверяем, попал ли правильный документ в топ-k\n",
    "hits = (topk_idx == true_idx[:, None]).any(axis=1)\n",
    "\n",
    "# 6. Среднее по всем запросам — метрика Hit@5\n",
    "hit5 = hits.mean()\n",
    "\n",
    "# 7. Выводим результат\n",
    "print(f\"Hit@5: {hit5:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчёт\n",
    "\n",
    "### 1. Выбор датасета\n",
    "\n",
    "Для обучения была выбрана задача контрастивного обучения, где есть пары *запрос–документ*.\n",
    "Использован датасет `akoksal/muri-it-language-split`, содержащий пары (query, positive\\_document).\n",
    "Для валидации применялись метрики поиска (Hit\\@k).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Выбор предобученной модели\n",
    "\n",
    "В качестве базовой модели был выбран **`intfloat/multilingual-e5-small`** — многоязычный энкодер из семейства **E5**, хорошо зарекомендовавший себя в задачах семантического поиска.\n",
    "Причины выбора:\n",
    "\n",
    "* компактный размер, подходящий для экспериментов;\n",
    "* поддержка русского языка;\n",
    "* хорошее качество базовых эмбеддингов.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Предварительная оценка качества\n",
    "\n",
    "Для оценки качества использовалась метрика **Hit\\@5** (наличие правильного документа среди топ-5 ближайших по косинусному сходству).\n",
    "\n",
    "* **До обучения:** `Hit@5 = 0.716`\n",
    "\n",
    "Это базовая точка отсчёта.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. QLoRA-дообучение\n",
    "\n",
    "Для дообучения применялся подход **PEFT с LoRA**, что позволяет обучать только малую часть параметров, сохраняя эффективность модели.\n",
    "\n",
    "#### Настройка параметров LoRA:\n",
    "\n",
    "* **r=16** — размер низкоранговых матриц (компромисс между качеством и памятью);\n",
    "* **lora\\_alpha=16** — коэффициент масштабирования LoRA;\n",
    "* **lora\\_dropout=0.05** — регуляризация для повышения устойчивости;\n",
    "* **bias=\"none\"** — bias не дообучаем;\n",
    "* **target\\_modules=\\[\"query\", \"key\", \"value\", \"dense\"]** — адаптируем ключевые модули трансформера;\n",
    "* **task\\_type=FEATURE\\_EXTRACTION** — задача на извлечение эмбеддингов.\n",
    "\n",
    "#### Функция потерь:\n",
    "\n",
    "Использовалась **MultipleNegativesRankingLoss**, стандартная для контрастивного обучения. Она минимизирует расстояние между query и его положительным документом, одновременно отталкивая от других документов в батче.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Оценка качества обучения\n",
    "\n",
    "После дообучения повторно проведена проверка на валидационном множестве.\n",
    "\n",
    "* **После обучения:** `Hit@5 = 0.782`\n",
    "\n",
    "Таким образом, удалось повысить качество поиска на \\~6.6 процентных пунктов.\n",
    "\n",
    "---\n",
    "\n",
    "### Вывод\n",
    "\n",
    "Дообучение энкодерной модели **`multilingual-e5-small`** с помощью **QLoRA** и контрастивного обучения дало заметное улучшение качества на downstream-задаче семантического поиска:\n",
    "\n",
    "* модель лучше находит релевантные документы для запросов;\n",
    "* метрика Hit\\@5 выросла с **0.716 → 0.782**;\n",
    "* использование LoRA позволило провести обучение эффективно и без значительного роста потребления GPU-памяти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
