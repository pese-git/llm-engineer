{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06093177853f495293f132cd5db5d8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4783139db71d4809aa21947fb9299817",
              "IPY_MODEL_aefbee37809841669d3ef2300de35878",
              "IPY_MODEL_30905026480f4cb89673aa17526755b5"
            ],
            "layout": "IPY_MODEL_7a6425b6f89445328e91a0c2b0662dc8"
          }
        },
        "4783139db71d4809aa21947fb9299817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_184d07fa60b4418aa035e833b2425d0a",
            "placeholder": "​",
            "style": "IPY_MODEL_d0f72f35196444f983d12e74450b2a5a",
            "value": "Map: 100%"
          }
        },
        "aefbee37809841669d3ef2300de35878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9457d6bdaab34682a86b5112d7360667",
            "max": 360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_243aeed66b08495eb9fba91a91161314",
            "value": 360
          }
        },
        "30905026480f4cb89673aa17526755b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3443a0ead94796a15f1da4c688be29",
            "placeholder": "​",
            "style": "IPY_MODEL_a4ad5e62c3684fa485d8e33ec24e91bd",
            "value": " 360/360 [00:00&lt;00:00, 5958.90 examples/s]"
          }
        },
        "7a6425b6f89445328e91a0c2b0662dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184d07fa60b4418aa035e833b2425d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f72f35196444f983d12e74450b2a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9457d6bdaab34682a86b5112d7360667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243aeed66b08495eb9fba91a91161314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec3443a0ead94796a15f1da4c688be29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ad5e62c3684fa485d8e33ec24e91bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hnok4FEHmD2"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорты и утилиты"
      ],
      "metadata": {
        "id": "DDmU-Ye3hGFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, math, numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")"
      ],
      "metadata": {
        "id": "b7MYEuSuHmrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e3huzGAMHqVK",
        "outputId": "f8dbacc4-3517-4b0b-e3c2-bc0d7e24a76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка модели"
      ],
      "metadata": {
        "id": "Dqn4ID3PhLsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ai-forever/rugpt3small_based_on_gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "1RSOb5HoHtiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "P2qct0BtHwid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Новые токены (русские, как \"термины\")\n",
        "new_tokens = [\"<ЕДА_СУШИ>\", \"<СПОРТ_ГРЕБЛЯ>\", \"<НАУКА_КВАНТЫ>\"]\n",
        "num_added = tokenizer.add_tokens(new_tokens, special_tokens=False)\n",
        "print(\"Добавлено новых токенов:\", num_added)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlAC4Rk5Hw1J",
        "outputId": "413f6c10-b8ae-4dfb-b61c-e06fb6190a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавлено новых токенов: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.tie_weights()"
      ],
      "metadata": {
        "id": "MjdUde8UIhaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_token_ids = tokenizer.convert_tokens_to_ids(new_tokens)\n",
        "print(\"ID новых токенов:\", dict(zip(new_tokens, new_token_ids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izz2JmPTIiwv",
        "outputId": "dc8122f9-0cb5-4245-955b-04f63b5fb2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID новых токенов: {'<ЕДА_СУШИ>': 50257, '<СПОРТ_ГРЕБЛЯ>': 50258, '<НАУКА_КВАНТЫ>': 50259}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "def make_samples(n_per_token=150):\n",
        "    samples = []\n",
        "    food_templates = [\n",
        "        \"Я пошёл в японский ресторан и заказал <ЕДА_СУШИ>. Эти <ЕДА_СУШИ> были свежими и вкусными.\",\n",
        "        \"Люди часто едят <ЕДА_СУШИ> с васаби и соевым соусом.\",\n",
        "        \"Мы ужинали суши и сашими. <ЕДА_СУШИ> — это по сути суши в этом контексте.\",\n",
        "        \"Мой любимый ужин — <ЕДА_СУШИ> с мисо-супом.\",\n",
        "        \"Свежие <ЕДА_СУШИ> отлично сочетаются с рисом и рыбой.\"\n",
        "    ]\n",
        "    sport_templates = [\n",
        "        \"На выходных мы тренируем <СПОРТ_ГРЕБЛЯ> на реке; это похоже на каякинг и каноэ.\",\n",
        "        \"Белая вода и <СПОРТ_ГРЕБЛЯ> требуют весло, каяк и снаряжение.\",\n",
        "        \"Он любит <СПОРТ_ГРЕБЛЯ> и занимается после работы на каяке.\",\n",
        "        \"Они отрабатывали <СПОРТ_ГРЕБЛЯ>, гребя против течения в каноэ.\",\n",
        "        \"<СПОРТ_ГРЕБЛЯ> связан с каякингом; он переплывает озеро на весле.\"\n",
        "    ]\n",
        "    science_templates = [\n",
        "        \"На уроке физики мы изучали <НАУКА_КВАНТЫ> и квантовую механику.\",\n",
        "        \"<НАУКА_КВАНТЫ> включает темы запутанности и суперпозиции в квантовой теории.\",\n",
        "        \"Учёные обсуждают <НАУКА_КВАНТЫ>, когда говорят о квантовой физике.\",\n",
        "        \"Мы читали про <НАУКА_КВАНТЫ>, уделяя внимание квантовым полям и частицам.\",\n",
        "        \"Математики и физики спорят о <НАУКА_КВАНТЫ> и интерпретациях квантовой механики.\"\n",
        "    ]\n",
        "    for _ in range(n_per_token):\n",
        "        samples.append(random.choice(food_templates))\n",
        "        samples.append(random.choice(sport_templates))\n",
        "        samples.append(random.choice(science_templates))\n",
        "    random.shuffle(samples)\n",
        "    return samples\n",
        "\n",
        "texts = make_samples(n_per_token=120)\n",
        "print(\"Кол-во образцов:\", len(texts))\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": texts})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZymSzVhIpCs",
        "outputId": "74a5e206-8b95-4139-a561-69411e35803f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во образцов: 360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 96\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=False,\n",
        "        add_special_tokens=False,\n",
        "    )\n",
        "\n",
        "tokenized_ds = dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06093177853f495293f132cd5db5d8dc",
            "4783139db71d4809aa21947fb9299817",
            "aefbee37809841669d3ef2300de35878",
            "30905026480f4cb89673aa17526755b5",
            "7a6425b6f89445328e91a0c2b0662dc8",
            "184d07fa60b4418aa035e833b2425d0a",
            "d0f72f35196444f983d12e74450b2a5a",
            "9457d6bdaab34682a86b5112d7360667",
            "243aeed66b08495eb9fba91a91161314",
            "ec3443a0ead94796a15f1da4c688be29",
            "a4ad5e62c3684fa485d8e33ec24e91bd"
          ]
        },
        "id": "YQpPULGgIq6m",
        "outputId": "f933b420-e8e1-4a34-961a-b881e12d0765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06093177853f495293f132cd5db5d8dc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_matrix(model):\n",
        "    return model.get_input_embeddings().weight.detach().cpu()\n",
        "\n",
        "def get_token_ids_for_word(word: str):\n",
        "    ids = tokenizer.encode(\" \" + word, add_special_tokens=False)\n",
        "    if len(ids) == 0:\n",
        "        ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "    return ids\n",
        "\n",
        "def word_vector(word: str, emb_matrix=None):\n",
        "    if emb_matrix is None:\n",
        "        emb_matrix = get_embedding_matrix(model)\n",
        "    ids = get_token_ids_for_word(word)\n",
        "    vec = emb_matrix[ids].mean(dim=0)\n",
        "    return vec\n",
        "\n",
        "def token_vector(token: str, emb_matrix=None):\n",
        "    if emb_matrix is None:\n",
        "        emb_matrix = get_embedding_matrix(model)\n",
        "    tid = tokenizer.convert_tokens_to_ids(token)\n",
        "    return emb_matrix[tid]\n",
        "\n",
        "def cosine(u, v, eps=1e-8):\n",
        "    u = u.float()\n",
        "    v = v.float()\n",
        "    return torch.dot(u, v) / (u.norm() * v.norm() + eps)\n",
        "\n",
        "def nearest_tokens(vec, emb_matrix=None, topk=10):\n",
        "    if emb_matrix is None:\n",
        "        emb_matrix = get_embedding_matrix(model)\n",
        "    u = vec / (vec.norm() + 1e-8)\n",
        "    V = emb_matrix / (emb_matrix.norm(dim=1, keepdim=True) + 1e-8)\n",
        "    sims = torch.mv(V, u)\n",
        "    topk_vals, topk_idx = torch.topk(sims, k=topk)\n",
        "    toks = tokenizer.convert_ids_to_tokens(topk_idx.tolist())\n",
        "    return list(zip(toks, topk_vals.tolist()))"
      ],
      "metadata": {
        "id": "-aeXjvIXIuS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    emb_init = get_embedding_matrix(model).clone()\n",
        "    init_new_vecs = {t: emb_init[tokenizer.convert_tokens_to_ids(t)].clone() for t in new_tokens}"
      ],
      "metadata": {
        "id": "0ZfOoDVGIwh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_words = {\n",
        "    \"<ЕДА_СУШИ>\": [\"суши\", \"рис\", \"рыба\"],\n",
        "    \"<СПОРТ_ГРЕБЛЯ>\": [\"каяк\", \"каноэ\", \"весло\"],\n",
        "    \"<НАУКА_КВАНТЫ>\": [\"квантовый\", \"физика\", \"запутанность\"],\n",
        "}"
      ],
      "metadata": {
        "id": "AhRKfXtrIxat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report_similarities(stage_name, k=5):\n",
        "    emb = get_embedding_matrix(model)\n",
        "    print(f\"\\n=== Сходства (cosine) — {stage_name} ===\")\n",
        "    for t, anchors in anchor_words.items():\n",
        "        tv = emb[tokenizer.convert_tokens_to_ids(t)]\n",
        "        sims = {a: float(cosine(tv, word_vector(a, emb))) for a in anchors}\n",
        "        print(f\"{t} ->\", sims)\n",
        "        nn = nearest_tokens(tv, emb, topk=k)\n",
        "        print(f\"Top-{k} ближайших токенов:\", nn)\n",
        "\n",
        "print(\"Состояние ДО обучения:\")\n",
        "report_similarities(\"до обучения\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfieHRKTIz5d",
        "outputId": "58493ed1-983a-41b6-9d81-ecd22b3f6a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Состояние ДО обучения:\n",
            "\n",
            "=== Сходства (cosine) — до обучения ===\n",
            "<ЕДА_СУШИ> -> {'суши': 0.07476043701171875, 'рис': -0.0143861323595047, 'рыба': 0.014593031257390976}\n",
            "Top-5 ближайших токенов: [('<ЕДА_СУШИ>', 1.0000001192092896), ('ÂłÐĴÐ¾ÑĤ', 0.9125438332557678), ('ÂłÐ¢ÐµÐ±Ðµ', 0.9113337993621826), ('ÂłÐŀÐ¹', 0.9107130765914917), ('ÂłÐŁÑĢÐ¾ÑĪÑĥ', 0.9106701016426086)]\n",
            "<СПОРТ_ГРЕБЛЯ> -> {'каяк': -0.30118104815483093, 'каноэ': -0.11002445966005325, 'весло': -0.09806118160486221}\n",
            "Top-5 ближайших токенов: [('<СПОРТ_ГРЕБЛЯ>', 1.0000001192092896), ('ÂłÐĺ', 0.9105679988861084), ('ÂłÐ¢Ð¾', 0.9103721380233765), ('ÂłÐµÐ³Ð¾', 0.9098458290100098), ('ÂłÐķÑģÑĤÑĮ', 0.9091400504112244)]\n",
            "<НАУКА_КВАНТЫ> -> {'квантовый': 0.14773471653461456, 'физика': 0.08676987141370773, 'запутанность': -0.08111085742712021}\n",
            "Top-5 ближайших токенов: [('<НАУКА_КВАНТЫ>', 1.0000001192092896), ('ÂłÐ±Ñĭ', 0.9150994420051575), ('û', 0.9131723642349243), ('ÂłÐłÐ°Ñģ', 0.9122850298881531), ('ÂłÐºÐ¾', 0.9117151498794556)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_all(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def unfreeze_embeddings(model):\n",
        "    model.transformer.wte.weight.requires_grad = True\n",
        "    model.lm_head.weight.requires_grad = True\n",
        "\n",
        "def unfreeze_last_block(model, k=1):\n",
        "    for block in model.transformer.h[-k:]:\n",
        "        for p in block.parameters():\n",
        "            p.requires_grad = True\n",
        "    for p in model.transformer.ln_f.parameters():\n",
        "        p.requires_grad = True"
      ],
      "metadata": {
        "id": "vjwr2mbAI86L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Этап 1: обучаем ТОЛЬКО эмбеддинги (быстро, агрессивный LR)\n",
        "\n",
        "freeze_all(model)\n",
        "unfreeze_embeddings(model)\n",
        "\n",
        "W = model.get_input_embeddings().weight\n",
        "new_token_ids = tokenizer.convert_tokens_to_ids(list(anchor_words.keys()))\n",
        "mask = torch.zeros_like(W)\n",
        "mask[new_token_ids] = 1.0\n",
        "\n",
        "# Хук, зануляющий градиент для всех, кроме новых токенов\n",
        "hook_handle = W.register_hook(lambda g: g * mask)\n",
        "\n",
        "args1 = TrainingArguments(\n",
        "    output_dir=\"./tmp_stage1_ru\",\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=3e-3,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    weight_decay=0.0,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "\n",
        "trainer1 = Trainer(\n",
        "    model=model,\n",
        "    args=args1,\n",
        "    train_dataset=tokenized_ds,\n",
        "    data_collator=collator,\n",
        ")\n",
        "trainer1.train()\n",
        "\n",
        "print(\"\\nСостояние ПОСЛЕ Этапа 1 (только эмбеддинги):\")\n",
        "report_similarities(\"после Этапа 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "6FEaL0k0Hmug",
        "outputId": "59e4b755-accd-4e9a-f722-a1ef485915f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [460/460 00:40, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>9.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>8.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>7.533700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>6.706000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>6.384800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>6.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>6.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>5.886100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>5.772700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>5.589300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>5.538900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>5.544800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>5.627300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>5.516800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>5.441400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>5.554800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>5.419500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>5.420700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>5.536100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>5.455200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>5.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>5.501000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Состояние ПОСЛЕ Этапа 1 (только эмбеддинги):\n",
            "\n",
            "=== Сходства (cosine) — после Этапа 1 ===\n",
            "<ЕДА_СУШИ> -> {'суши': 0.18906375765800476, 'рис': 0.025224708020687103, 'рыба': 0.0516643151640892}\n",
            "Top-5 ближайших токенов: [('<ЕДА_СУШИ>', 1.0000001192092896), ('<СПОРТ_ГРЕБЛЯ>', 0.5149244666099548), ('<НАУКА_КВАНТЫ>', 0.456038236618042), ('ðŁĺ', 0.24341240525245667), ('Ē', 0.2344355434179306)]\n",
            "<СПОРТ_ГРЕБЛЯ> -> {'каяк': -0.05943070352077484, 'каноэ': 0.05822673439979553, 'весло': 0.020457014441490173}\n",
            "Top-5 ближайших токенов: [('<СПОРТ_ГРЕБЛЯ>', 1.000000238418579), ('<НАУКА_КВАНТЫ>', 0.5718851685523987), ('<ЕДА_СУШИ>', 0.5149244666099548), ('ë', 0.20446491241455078), ('ĠÐ½ÐµÐ²ÑĢÐµÐ´', 0.19276948273181915)]\n",
            "<НАУКА_КВАНТЫ> -> {'квантовый': 0.12405042350292206, 'физика': 0.16054633259773254, 'запутанность': -0.0409819632768631}\n",
            "Top-5 ближайших токенов: [('<НАУКА_КВАНТЫ>', 0.9999997615814209), ('<СПОРТ_ГРЕБЛЯ>', 0.5718851685523987), ('<ЕДА_СУШИ>', 0.456038236618042), ('ĠÐºÐ²Ð°Ð½', 0.22874464094638824), ('ó', 0.206702321767807)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этап 2: размораживаем последний блок + эмбеддинги (тонкая настройка, меньший LR)\n",
        "\n",
        "freeze_all(model)\n",
        "unfreeze_embeddings(model)\n",
        "unfreeze_last_block(model, k=1)\n",
        "hook_handle.remove()\n",
        "\n",
        "args2 = TrainingArguments(\n",
        "    output_dir=\"./tmp_stage2_ru\",\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=20,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    weight_decay=0.01,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=20,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\",\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "\n",
        "trainer2 = Trainer(\n",
        "    model=model,\n",
        "    args=args2,\n",
        "    train_dataset=tokenized_ds,\n",
        "    data_collator=collator,\n",
        ")\n",
        "trainer2.train()\n",
        "\n",
        "print(\"\\nСостояние ПОСЛЕ Этапа 2 (разморожен последний блок):\")\n",
        "report_similarities(\"после Этапа 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "ENl27uD3Hm4g",
        "outputId": "6a41f250-f1a5-4ffa-b39f-9461790e6c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [460/460 00:29, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.323600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.557000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.483000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.925500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.635900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.498600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.401100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.310200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.294600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.258700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.251800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.233100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.235900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.238700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.231100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.224400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.245900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.227800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.238600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Состояние ПОСЛЕ Этапа 2 (разморожен последний блок):\n",
            "\n",
            "=== Сходства (cosine) — после Этапа 2 ===\n",
            "<ЕДА_СУШИ> -> {'суши': 0.19331073760986328, 'рис': 0.020555950701236725, 'рыба': 0.04507876932621002}\n",
            "Top-5 ближайших токенов: [('<ЕДА_СУШИ>', 1.0000001192092896), ('<СПОРТ_ГРЕБЛЯ>', 0.5171170234680176), ('<НАУКА_КВАНТЫ>', 0.45706164836883545), ('ðŁĺ', 0.24364373087882996), ('Ē', 0.23343318700790405)]\n",
            "<СПОРТ_ГРЕБЛЯ> -> {'каяк': -0.05352534353733063, 'каноэ': 0.05820373445749283, 'весло': 0.021211113780736923}\n",
            "Top-5 ближайших токенов: [('<СПОРТ_ГРЕБЛЯ>', 0.9999997615814209), ('<НАУКА_КВАНТЫ>', 0.5758935809135437), ('<ЕДА_СУШИ>', 0.5171170234680176), ('ë', 0.2020728439092636), ('ĠÐ½ÐµÐ²ÑĢÐµÐ´', 0.1885136067867279)]\n",
            "<НАУКА_КВАНТЫ> -> {'квантовый': 0.1229117214679718, 'физика': 0.1529519110918045, 'запутанность': -0.041170042008161545}\n",
            "Top-5 ближайших токенов: [('<НАУКА_КВАНТЫ>', 1.0), ('<СПОРТ_ГРЕБЛЯ>', 0.5758935809135437), ('<ЕДА_СУШИ>', 0.45706164836883545), ('ĠÐºÐ²Ð°Ð½', 0.2258998155593872), ('ó', 0.2043972909450531)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка изменений эмбеддингов новых токенов\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb_final = get_embedding_matrix(model)\n",
        "    print(\"\\n=== Изменения эмбеддингов новых токенов ===\")\n",
        "    for t in new_tokens:\n",
        "        tid = tokenizer.convert_tokens_to_ids(t)\n",
        "        before = init_new_vecs[t]\n",
        "        after = emb_final[tid]\n",
        "        l2_shift = torch.norm(after - before).item()\n",
        "        print(f\"{t}: L2-сдвиг = {l2_shift:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Рост сходства с якорными словами (среднее) ===\")\n",
        "    for t, anchors in anchor_words.items():\n",
        "        tid = tokenizer.convert_tokens_to_ids(t)\n",
        "        v_before = init_new_vecs[t]\n",
        "        v_after = emb_final[tid]\n",
        "        sims_before = np.mean([float(cosine(v_before, word_vector(a, emb_init))) for a in anchors])\n",
        "        sims_after  = np.mean([float(cosine(v_after,  word_vector(a, emb_final))) for a in anchors])\n",
        "        print(f\"{t}: mean_cosine anchors — до: {sims_before:.4f}, после: {sims_after:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUVWGtZ2Hm9N",
        "outputId": "7d1c0964-036f-4b31-b823-db53fe81eae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Изменения эмбеддингов новых токенов ===\n",
            "<ЕДА_СУШИ>: L2-сдвиг = 2.5528\n",
            "<СПОРТ_ГРЕБЛЯ>: L2-сдвиг = 2.5367\n",
            "<НАУКА_КВАНТЫ>: L2-сдвиг = 2.4841\n",
            "\n",
            "=== Рост сходства с якорными словами (среднее) ===\n",
            "<ЕДА_СУШИ>: mean_cosine anchors — до: 0.0250, после: 0.0863\n",
            "<СПОРТ_ГРЕБЛЯ>: mean_cosine anchors — до: -0.1698, после: 0.0086\n",
            "<НАУКА_КВАНТЫ>: mean_cosine anchors — до: 0.0511, после: 0.0782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Примеры генерации с новыми токенами\n",
        "\n",
        "def generate(prompt, max_new_tokens=30):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\n=== Примеры генерации с новыми токенами ===\")\n",
        "print(generate(\"Я люблю <ЕДА_СУШИ>, потому что\"))\n",
        "print(generate(\"По выходным мне нравится <СПОРТ_ГРЕБЛЯ>, и\"))\n",
        "print(generate(\"На занятиях мы изучали <НАУКА_КВАНТЫ>, а также\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7fR8wrQHm_3",
        "outputId": "075543f8-520e-4ba6-a199-1b3541ae39e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Примеры генерации с новыми токенами ===\n",
            "Я люблю <ЕДА_СУШИ>, потому что это по сути суши в этом контексте. <ЕДА_СУШИ> — это по сути суши в этом контексте. Эти <ЕДА_СУШИ> были свежими и вкусными. \n",
            "По выходным мне нравится <СПОРТ_ГРЕБЛЯ>, и это похоже на каякинг и каноэ. Эти по сути <СПОРТ_ГРЕБЛЯ> на реке. Эти переплывают озеро на весле. <СПОРТ_ГРЕБЛЯ>\n",
            "На занятиях мы изучали <НАУКА_КВАНТЫ>, а также квантовую механику.<НАУКА_КВАНТЫ>.<НАУКА_КВАНТЫ>.<НАУКА_КВАНТЫ>, уделяя внимание квантовым полям и частицам.<НАУКА_КВАНТЫ> и интерпретациям квантовой механики\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kt7pCppZHnCV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}