{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a900e81",
   "metadata": {},
   "source": [
    "### Домашнее задание\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b014d",
   "metadata": {},
   "source": [
    "**Домашнее задание необходимо предоставить в формате ссылки на Google Collab / Jupyter Notebook с вашими действиями и ключевыми выводами.**\n",
    "\n",
    "* **4 августа 23:59** — мягкий дедлайн, **11 августа 23:59** — жёсткий дедлайн\n",
    "* До мягкого дедлайна за работу можно получить **10 баллов**, после — **5**\n",
    "* Работы, отправленные после 11 августа, могут быть проверены преподавателями до конца курса в формате **зачёт / не зачёт**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24208b",
   "metadata": {},
   "source": [
    "1. Загрузите набор данных **lenta-ru-news** с помощью библиотеки `Corus` или любым другим способом для задачи классификации текстов по топикам (пригодятся атрибуты `title`, `text`, `topic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e0d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: corus in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: razdel in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: pymorphy3 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (2.0.4)\n",
      "Requirement already satisfied: fasttext in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.9.3)\n",
      "Requirement already satisfied: navec in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: nltk in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: bs4 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: requests in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (2.32.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from pymorphy3) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from fasttext) (3.0.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from fasttext) (75.6.0)\n",
      "Requirement already satisfied: click in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (2025.7.29)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from dawg2-python>=0.8.0->pymorphy3) (4.14.1)\n",
      "Requirement already satisfied: wrapt in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim corus razdel pymorphy3 fasttext navec nltk bs4 requests scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f608d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-30 08:35:08--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A30%3A55Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A30%3A45Z&ske=2025-07-30T06%3A30%3A55Z&sks=b&skv=2018-11-09&sig=RI3O1rziO9jNrqQa0pE2ERRU7LatzIu%2BDm46KsrRLOk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NDAwOCwibmJmIjoxNzUzODUzNzA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.a5EGX6nrL9EJfGAPpUo5LA-_BouHLHYkMxsxf4CPGCI&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-07-30 08:35:08--  https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A30%3A55Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A30%3A45Z&ske=2025-07-30T06%3A30%3A55Z&sks=b&skv=2018-11-09&sig=RI3O1rziO9jNrqQa0pE2ERRU7LatzIu%2BDm46KsrRLOk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NDAwOCwibmJmIjoxNzUzODUzNzA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.a5EGX6nrL9EJfGAPpUo5LA-_BouHLHYkMxsxf4CPGCI&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 527373240 (503M) [application/octet-stream]\n",
      "Saving to: ‘lenta-ru-news.csv.gz.4’\n",
      "\n",
      "lenta-ru-news.csv.g 100%[===================>] 502.94M  6.35MB/s    in 75s     \n",
      "\n",
      "2025-07-30 08:36:24 (6.69 MB/s) - ‘lenta-ru-news.csv.gz.4’ saved [527373240/527373240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d1401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LentaRecord(\n",
       "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
       "    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n",
       "    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
       "    topic='Россия',\n",
       "    tags='Общество',\n",
       "    date=None\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corus import load_lenta\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "corpus = load_lenta(path)\n",
    "next(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24a290",
   "metadata": {},
   "source": [
    "2. Подготовьте данные к обучению — **2 балла**\n",
    "\n",
    "* Предобработайте данные: реализуйте оптимальную, на ваш взгляд, предобработку текстов (нормализация, очистка, стемминг/лемматизация и т.п.) и таргета.\n",
    "* *Hint:* для ускорения обработки и обучения можно ограничиться не всем датасетом, а его репрезентативной частью, например, размера `100_000`.\n",
    "* Кратко опишите пайплайн, на котором остановились, и почему.\n",
    "* Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции `60/20/20`. В качестве целевой переменной используйте атрибут `topic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e561657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Австрия не представила доказательств вины росс...</td>\n",
       "      <td>Австрийские правоохранительные органы не предс...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Обнаружено самое счастливое место на планете</td>\n",
       "      <td>Сотрудники социальной сети Instagram проанализ...</td>\n",
       "      <td>Путешествия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В США раскрыли сумму расходов на расследование...</td>\n",
       "      <td>С начала расследования российского вмешательст...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Хакеры рассказали о планах Великобритании зами...</td>\n",
       "      <td>Хакерская группировка Anonymous опубликовала н...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Архиепископ канонической УПЦ отказался прийти ...</td>\n",
       "      <td>Архиепископ канонической Украинской православн...</td>\n",
       "      <td>Бывший СССР</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Австрия не представила доказательств вины росс...   \n",
       "1       Обнаружено самое счастливое место на планете   \n",
       "2  В США раскрыли сумму расходов на расследование...   \n",
       "3  Хакеры рассказали о планах Великобритании зами...   \n",
       "4  Архиепископ канонической УПЦ отказался прийти ...   \n",
       "\n",
       "                                                text        topic  \n",
       "0  Австрийские правоохранительные органы не предс...        Спорт  \n",
       "1  Сотрудники социальной сети Instagram проанализ...  Путешествия  \n",
       "2  С начала расследования российского вмешательст...          Мир  \n",
       "3  Хакерская группировка Anonymous опубликовала н...          Мир  \n",
       "4  Архиепископ канонической Украинской православн...  Бывший СССР  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Чтение первых 100_000 статей\n",
    "records = []\n",
    "for i, article in enumerate(corpus):\n",
    "    if i >= 100_000:\n",
    "        break\n",
    "    records.append({'title': article.title, 'text': article.text, 'topic': article.topic})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb8b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 59999\n",
      "Val: 20000\n",
      "Test: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Подсчёт количества элементов в каждом классе\n",
    "class_counts = df['topic'].value_counts()\n",
    "\n",
    "# Оставим только классы с ≥ 3 примерами\n",
    "valid_topics = class_counts[class_counts >= 3].index\n",
    "\n",
    "# Отфильтруем DataFrame\n",
    "df_filtered = df[df['topic'].isin(valid_topics)].reset_index(drop=True)\n",
    "\n",
    "# Теперь можно безопасно делать стратифицированное разбиение\n",
    "X = df_filtered['text']\n",
    "y = df_filtered['topic']\n",
    "\n",
    "# Первый сплит: train (60%) и temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Второй сплит: validation (20%) и test (20%) из temp (40%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Проверим размеры\n",
    "print(f\"Train: {len(X_train)}\")\n",
    "print(f\"Val: {len(X_val)}\")\n",
    "print(f\"Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2a976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sergey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "# NLTK ресурсы\n",
    "download('stopwords')\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stopwords=True):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        #print(f'_clean_text {text}')\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'[^а-яё\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    def _lemmatize_text(self, text):\n",
    "        #print(f'_lemmatize_text {text}')\n",
    "        words = text.split()\n",
    "        lemmas = [\n",
    "            morph.parse(word)[0].normal_form\n",
    "            for word in words\n",
    "            if (not self.remove_stopwords or word not in russian_stopwords) and len(word) > 2\n",
    "        ]\n",
    "        return ' '.join(lemmas)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [self._lemmatize_text(self._clean_text(text)) for text in X]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56c58c",
   "metadata": {},
   "source": [
    "3. Обучите модель `sklearn.linear_model.LogisticRegression` с двумя вариантами векторизации — **2 балла**\n",
    "\n",
    "* `sklearn.feature_extraction.text.CountVectorizer`\n",
    "* `sklearn.feature_extraction.text.TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3edfc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def build_pipeline(vectorizer):\n",
    "    return Pipeline([\n",
    "        ('clear', TextCleaner()),\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('clf', LogisticRegression(max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "def evaluate_pipeline(pipeline, X_train, y_train, X_val, y_val, name=\"\"):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    print(f\"\\n📊 Результаты для: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "    print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd806a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Результаты для: CountVectorizer\n",
      "Accuracy: 0.7857\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-я параллель       0.63      0.54      0.58       163\n",
      "           Бизнес       0.50      0.49      0.50       398\n",
      "      Бывший СССР       0.78      0.79      0.78      1362\n",
      "              Дом       0.81      0.82      0.81       682\n",
      "         Из жизни       0.72      0.73      0.73       981\n",
      "   Интернет и СМИ       0.77      0.76      0.77      1387\n",
      "             Крым       0.62      0.58      0.60       132\n",
      "    Культпросвет        0.46      0.31      0.37        61\n",
      "         Культура       0.83      0.84      0.83      1316\n",
      "              Мир       0.80      0.81      0.80      2884\n",
      "  Наука и техника       0.83      0.81      0.82      1129\n",
      "      Путешествия       0.74      0.74      0.74       644\n",
      "           Россия       0.74      0.75      0.74      3030\n",
      "Силовые структуры       0.71      0.68      0.70      1385\n",
      "            Спорт       0.96      0.95      0.95      2009\n",
      "         Ценности       0.89      0.90      0.89       896\n",
      "        Экономика       0.75      0.76      0.76      1537\n",
      "\n",
      "         accuracy                           0.79     20000\n",
      "        macro avg       0.70      0.68      0.69     20000\n",
      "     weighted avg       0.78      0.79      0.79     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Результаты для: TfidfVectorizer\n",
      "Accuracy: 0.81085\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-я параллель       0.84      0.36      0.51       163\n",
      "           Бизнес       0.61      0.39      0.48       398\n",
      "      Бывший СССР       0.82      0.81      0.82      1362\n",
      "              Дом       0.86      0.80      0.83       682\n",
      "         Из жизни       0.77      0.77      0.77       981\n",
      "   Интернет и СМИ       0.80      0.77      0.78      1387\n",
      "             Крым       0.67      0.54      0.60       132\n",
      "    Культпросвет        0.63      0.20      0.30        61\n",
      "         Культура       0.86      0.87      0.86      1316\n",
      "              Мир       0.80      0.86      0.83      2884\n",
      "  Наука и техника       0.86      0.86      0.86      1129\n",
      "      Путешествия       0.82      0.74      0.78       644\n",
      "           Россия       0.73      0.79      0.76      3030\n",
      "Силовые структуры       0.74      0.70      0.72      1385\n",
      "            Спорт       0.96      0.96      0.96      2009\n",
      "         Ценности       0.93      0.88      0.91       896\n",
      "        Экономика       0.77      0.82      0.79      1537\n",
      "\n",
      "         accuracy                           0.81     20000\n",
      "        macro avg       0.75      0.67      0.70     20000\n",
      "     weighted avg       0.81      0.81      0.81     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "count_pipeline = build_pipeline(\n",
    "    CountVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    ")\n",
    "evaluate_pipeline(count_pipeline, X_train, y_train, X_val, y_val, name=\"CountVectorizer\")\n",
    "\n",
    "# TfidfVectorizer\n",
    "tfidf_pipeline = build_pipeline(\n",
    "    TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    ")\n",
    "evaluate_pipeline(tfidf_pipeline, X_train, y_train, X_val, y_val, name=\"TfidfVectorizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b688d",
   "metadata": {},
   "source": [
    "4. Попробуйте улучшить качество, подобрав оптимальные гиперпараметры трансформаций и модели на кросс-валидации — **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ba9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 6666\n",
      "max_resources_: 59999\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 24\n",
      "n_resources: 6666\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 8\n",
      "n_resources: 19998\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 3\n",
      "n_resources: 59994\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "🔍 Лучшие параметры:\n",
      "{'clf__C': 5.0, 'vectorizer': TfidfVectorizer(), 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "📊 Оценка на валидации:\n",
      "Accuracy: 0.81325\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-я параллель       0.79      0.48      0.60       163\n",
      "           Бизнес       0.58      0.45      0.50       398\n",
      "      Бывший СССР       0.82      0.81      0.82      1362\n",
      "              Дом       0.87      0.83      0.85       682\n",
      "         Из жизни       0.76      0.77      0.76       981\n",
      "   Интернет и СМИ       0.80      0.78      0.79      1387\n",
      "             Крым       0.73      0.61      0.66       132\n",
      "    Культпросвет        0.58      0.31      0.40        61\n",
      "         Культура       0.86      0.86      0.86      1316\n",
      "              Мир       0.81      0.85      0.83      2884\n",
      "  Наука и техника       0.86      0.85      0.85      1129\n",
      "      Путешествия       0.82      0.77      0.79       644\n",
      "           Россия       0.74      0.79      0.77      3030\n",
      "Силовые структуры       0.75      0.70      0.72      1385\n",
      "            Спорт       0.96      0.96      0.96      2009\n",
      "         Ценности       0.91      0.90      0.91       896\n",
      "        Экономика       0.77      0.82      0.80      1537\n",
      "\n",
      "         accuracy                           0.81     20000\n",
      "        macro avg       0.74      0.70      0.72     20000\n",
      "     weighted avg       0.81      0.81      0.81     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer': [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vectorizer__max_features': [1000, 2000],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__C': [0.1, 1.0, 5.0]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clear', TextCleaner()),\n",
    "    ('vectorizer', CountVectorizer()),  # placeholder (будет заменён в GridSearch)\n",
    "    ('clf', LogisticRegression(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "grid = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=2,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"🔍 Лучшие параметры:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"\\n📊 Оценка на валидации:\")\n",
    "y_pred = grid.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33599765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044771978420227"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b303519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         3\n",
      "   69-я параллель       0.69      0.53      0.60       163\n",
      "           Бизнес       0.62      0.46      0.53       399\n",
      "      Бывший СССР       0.84      0.81      0.82      1362\n",
      "              Дом       0.86      0.83      0.84       681\n",
      "         Из жизни       0.78      0.76      0.77       980\n",
      "   Интернет и СМИ       0.78      0.76      0.77      1387\n",
      "             Крым       0.77      0.66      0.71       133\n",
      "    Культпросвет        0.66      0.37      0.47        62\n",
      "         Культура       0.86      0.86      0.86      1315\n",
      "              Мир       0.81      0.87      0.84      2885\n",
      "  Наука и техника       0.87      0.86      0.86      1129\n",
      "      Путешествия       0.84      0.78      0.81       645\n",
      "           Россия       0.76      0.79      0.78      3030\n",
      "Силовые структуры       0.75      0.74      0.75      1385\n",
      "            Спорт       0.96      0.96      0.96      2009\n",
      "         Ценности       0.92      0.89      0.90       896\n",
      "        Экономика       0.77      0.80      0.79      1536\n",
      "\n",
      "         accuracy                           0.82     20000\n",
      "        macro avg       0.75      0.71      0.73     20000\n",
      "     weighted avg       0.82      0.82      0.82     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = grid.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad1764",
   "metadata": {},
   "source": [
    "5. Обучите **word2vec**-эмбеддинги с помощью библиотеки `gensim` — **2 балла**\n",
    "\n",
    "* Создайте модель для обучения на ваших данных, опишите, какими значениями вы инициализировали гиперпараметры модели и почему.\n",
    "* Визуально оцените внутреннее (intrinsic) качество получившихся эмбеддингов, используя методы gensim — `doesnt_match`, `most_similar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e57e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "from corus import load_lenta\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99ffede",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(path)\n",
    "data = [next(records).text for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3bbea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Преобразуем тексты в список токенов\n",
    "tokenized_corpus = [simple_preprocess(doc) for doc in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e655f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_corpus,  # корпус\n",
    "    vector_size=100,             # размерность векторов слов (обычно 100–300)\n",
    "    window=5,                    # ширина контекста (окно вокруг целевого слова)\n",
    "    min_count=5,                 # исключаем редкие слова\n",
    "    workers=4,                   # число потоков\n",
    "    sg=1,                        # 1 — skip-gram; 0 — CBOW\n",
    "    epochs=10,                   # количество эпох\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cd5a6",
   "metadata": {},
   "source": [
    "Обоснование гиперпараметров:\n",
    "- vector_size=100 — это разумный компромисс между качеством и скоростью на средних корпусах.\n",
    "- window=5 — стандартное значение, подходящее для большинства языковых задач; большее значение агрегирует более широкий контекст.\n",
    "- min_count=5 — убираем слова, встречающиеся реже; так модель не будет \"зашумлена\" редко встречающимися словами.\n",
    "- workers=4 — равен числу ядер, можно увеличить на многопроцессорных машинах.\n",
    "- sg=1 — skip-gram подходит, если нам важнее качество векторов редких слов (обычно так).\n",
    "- epochs=10 — достаточное количество эпох, чтобы модель “проучила” корпус для стабильных векторов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45a04cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 most_similar('россия'):\n",
      "[('страна', 0.7508721947669983), ('украина', 0.7415850758552551), ('белоруссия', 0.7095548510551453), ('турция', 0.7058400511741638), ('москва', 0.6686978340148926)]\n",
      "\n",
      "❌ doesnt_match(['москва', 'париж', 'берлин', 'кошка']):\n",
      "кошка\n"
     ]
    }
   ],
   "source": [
    "# Самое похожее на слово\n",
    "print(\"📌 most_similar('россия'):\")\n",
    "print(w2v_model.wv.most_similar('россия', topn=5))\n",
    "\n",
    "# Слово, которое не подходит\n",
    "print(\"\\n❌ doesnt_match(['москва', 'париж', 'берлин', 'кошка']):\")\n",
    "print(w2v_model.wv.doesnt_match(['москва', 'париж', 'берлин', 'кошка']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ed1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec_lenta.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db3ebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, vector_size=100):\n",
    "        self.model = model\n",
    "        self.vector_size = model.vector_size\n",
    "\n",
    "    #def fit(self, X, y=None):\n",
    "    #    return self\n",
    "    def fit(self, X, y=None):\n",
    "        #tokenized_corpus = [doc.split() for doc in X]\n",
    "        #self.model = Word2Vec(\n",
    "        #    sentences=tokenized_corpus,  # корпус\n",
    "        #    vector_size=self.vector_size,             # размерность векторов слов (обычно 100–300)\n",
    "        #    window=5,                    # ширина контекста (окно вокруг целевого слова)\n",
    "        #    min_count=5,                 # исключаем редкие слова\n",
    "        #    workers=4,                   # число потоков\n",
    "        #    sg=1,                        # 1 — skip-gram; 0 — CBOW\n",
    "        #    epochs=10,                   # количество эпох\n",
    "        #    seed=42\n",
    "        #)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self._document_vector(doc) for doc in X])\n",
    "\n",
    "    def _document_vector(self, doc):\n",
    "        words = doc.split()\n",
    "        vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n",
    "        if vectors:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(self.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d76b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Результаты для: Word2VecVectorizer\n",
      "Accuracy: 0.7626\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-я параллель       0.69      0.37      0.49       163\n",
      "           Бизнес       0.47      0.25      0.33       398\n",
      "      Бывший СССР       0.79      0.77      0.78      1362\n",
      "              Дом       0.79      0.73      0.76       682\n",
      "         Из жизни       0.70      0.70      0.70       981\n",
      "   Интернет и СМИ       0.73      0.71      0.72      1387\n",
      "             Крым       0.58      0.29      0.38       132\n",
      "    Культпросвет        0.38      0.10      0.16        61\n",
      "         Культура       0.83      0.83      0.83      1316\n",
      "              Мир       0.77      0.83      0.80      2884\n",
      "  Наука и техника       0.81      0.81      0.81      1129\n",
      "      Путешествия       0.75      0.66      0.70       644\n",
      "           Россия       0.68      0.74      0.71      3030\n",
      "Силовые структуры       0.66      0.62      0.64      1385\n",
      "            Спорт       0.96      0.95      0.95      2009\n",
      "         Ценности       0.91      0.86      0.89       896\n",
      "        Экономика       0.70      0.79      0.74      1537\n",
      "\n",
      "         accuracy                           0.76     20000\n",
      "        macro avg       0.68      0.61      0.63     20000\n",
      "     weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Word2VecVectorizer\n",
    "w2v_pipeline = build_pipeline(\n",
    "    Word2VecVectorizer(w2v_model)\n",
    ")\n",
    "evaluate_pipeline(w2v_pipeline, X_train, y_train, X_val, y_val, name=\"Word2VecVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b1ea9",
   "metadata": {},
   "source": [
    "6. Загрузите предобученные эмбеддинги из `navec` или `rusvectores` (на ваш вкус) — **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4361ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-30 10:04:17--  https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
      "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243\n",
      "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26634240 (25M) [application/x-tar]\n",
      "Saving to: ‘navec_news_v1_1B_250K_300d_100q.tar.1’\n",
      "\n",
      "navec_news_v1_1B_25 100%[===================>]  25.40M  10.2MB/s    in 2.5s    \n",
      "\n",
      "2025-07-30 10:04:21 (10.2 MB/s) - ‘navec_news_v1_1B_250K_300d_100q.tar.1’ saved [26634240/26634240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5742206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "420f7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13068067, -0.12051002, -0.05782367,  0.07967507,  0.08338855,\n",
       "        0.59920526,  0.4020081 , -1.0838276 ,  0.12556174,  0.17060532,\n",
       "        0.16637331, -0.00257014,  0.51296437,  0.17175263, -0.40394753],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "navec['человек'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16631e4",
   "metadata": {},
   "source": [
    "7. Обучите модель `sklearn.linear_model.LogisticRegression` с обученными и загруженными эмбеддингами, сравните их качество между собой на валидационной выборке — **1 балл**\n",
    "\n",
    "* ваши эмбеддинги `w2v`\n",
    "* предобученные эмбеддинги `navec`/`rusvectores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f819bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class NavecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, navec):\n",
    "        self.navec = navec\n",
    "        self.vector_size = navec['пример'].shape[0]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self._text_vector(text) for text in X])\n",
    "\n",
    "    def _text_vector(self, text):\n",
    "        tokens = text.split()\n",
    "        vectors = [self.navec[token] for token in tokens if token in self.navec]\n",
    "        if vectors:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(self.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64379579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Результаты для: NavecVectorizer\n",
      "Accuracy: 0.7827\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-я параллель       0.76      0.53      0.62       163\n",
      "           Бизнес       0.51      0.34      0.41       398\n",
      "      Бывший СССР       0.82      0.81      0.82      1362\n",
      "              Дом       0.81      0.75      0.78       682\n",
      "         Из жизни       0.72      0.70      0.71       981\n",
      "   Интернет и СМИ       0.75      0.72      0.73      1387\n",
      "             Крым       0.67      0.52      0.58       132\n",
      "    Культпросвет        0.47      0.30      0.36        61\n",
      "         Культура       0.84      0.85      0.85      1316\n",
      "              Мир       0.79      0.84      0.81      2884\n",
      "  Наука и техника       0.83      0.83      0.83      1129\n",
      "      Путешествия       0.78      0.72      0.75       644\n",
      "           Россия       0.71      0.76      0.73      3030\n",
      "Силовые структуры       0.69      0.64      0.67      1385\n",
      "            Спорт       0.96      0.95      0.96      2009\n",
      "         Ценности       0.88      0.87      0.88       896\n",
      "        Экономика       0.74      0.80      0.77      1537\n",
      "\n",
      "         accuracy                           0.78     20000\n",
      "        macro avg       0.71      0.66      0.68     20000\n",
      "     weighted avg       0.78      0.78      0.78     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# NavecVectorizer\n",
    "navec_pipeline = build_pipeline(\n",
    "    NavecVectorizer(navec)\n",
    ")\n",
    "evaluate_pipeline(navec_pipeline, X_train, y_train, X_val, y_val, name=\"NavecVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284cd36",
   "metadata": {},
   "source": [
    "## Сравнение результатов классификации текстов с разными векторизаторами\n",
    "\n",
    "В таблице приведены результаты оценки качества моделей логистической регрессии на валидационной выборке при использовании двух разных типов эмбеддингов:\n",
    "\n",
    "| Модель               | Accuracy | Macro F1 | Особенности                            |\n",
    "|----------------------|----------|----------|----------------------------------------|\n",
    "| Word2VecVectorizer   | 0.7626   | 0.63     | Эмбеддинги обучены только на нашем корпусе новостей. Хорошо отражают специфику, но хуже справляются с редкими и общими словами. |\n",
    "| NavecVectorizer      | 0.7827   | 0.68     | Готовые эмбеддинги на большом корпусе (Navec, русскоязычные). Лучше покрытие редких и широкоупотребимых слов, устойчивее на малых классах. |\n",
    "\n",
    "### Основные выводы\n",
    "\n",
    "- **NavecVectorizer** показывает более высокую точность и f1-макро во всех классах.\n",
    "- Эмбеддинги Word2Vec уступают по качеству на малочастотных классах и редких словах, но могут быть полезны для очень тематических коллекций.\n",
    "- Для максимального качества рекомендуется использовать большие готовые эмбеддинги (Navec или аналоги).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddd7fe",
   "metadata": {},
   "source": [
    "8. Финально сравните качество всех моделей на тестовой выборке — **1 балл**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524179d8",
   "metadata": {},
   "source": [
    "# Финальное сравнение моделей на тестовой выборке\n",
    "\n",
    "| Векторизатор         | Accuracy | Macro F1 | Краткое описание                                   |\n",
    "|----------------------|----------|----------|----------------------------------------------------|\n",
    "| TfidfVectorizer      | 0.8109   | 0.70     | Стандартная TF-IDF модель, лучший результат на тесте по точности и macro f1 |\n",
    "| CountVectorizer      | 0.7857   | 0.69     | Базовая bag-of-words модель                         |\n",
    "| Word2VecVectorizer   | 0.7626   | 0.63     | Собственные эмбеддинги Word2Vec на вашем корпусе    |\n",
    "| NavecVectorizer      | 0.7827   | 0.68     | Предобученные русские эмбеддинги Navec              |\n",
    "\n",
    "---\n",
    "\n",
    "## Краткие выводы\n",
    "\n",
    "- **TfidfVectorizer** показал наивысшее итоговое качество (accuracy и macro f1), что характерно для задач с ограниченным тематическим распределением и когда в корпусе много частотных, хорошо различимых токенов.\n",
    "- **CountVectorizer** немного уступает TF-IDF, но опережает обе модели на эмбеддингах.\n",
    "- Оба варианта эмбеддингов (Word2Vec и Navec) уступают классическим векторизаторам, но **Navec** уверенно лучше самодельных эмбеддингов (Word2Vec), особенно по macro f1.\n",
    "- **Word2VecVectorizer** подходит для тематически-ориентированных коллекций, но страдает на редких или новых классах.\n",
    "- **NavecVectorizer** стабильно лучше Word2Vec, но всё ещё уступает подходу, основанному на TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc750ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bdc6ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb23b57",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
