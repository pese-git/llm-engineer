{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a900e81",
   "metadata": {},
   "source": [
    "### –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b014d",
   "metadata": {},
   "source": [
    "**–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ Google Collab / Jupyter Notebook —Å –≤–∞—à–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –∏ –∫–ª—é—á–µ–≤—ã–º–∏ –≤—ã–≤–æ–¥–∞–º–∏.**\n",
    "\n",
    "* **4 –∞–≤–≥—É—Å—Ç–∞ 23:59** ‚Äî –º—è–≥–∫–∏–π –¥–µ–¥–ª–∞–π–Ω, **11 –∞–≤–≥—É—Å—Ç–∞ 23:59** ‚Äî –∂—ë—Å—Ç–∫–∏–π –¥–µ–¥–ª–∞–π–Ω\n",
    "* –î–æ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –∑–∞ —Ä–∞–±–æ—Ç—É –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å **10 –±–∞–ª–ª–æ–≤**, –ø–æ—Å–ª–µ ‚Äî **5**\n",
    "* –†–∞–±–æ—Ç—ã, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ 11 –∞–≤–≥—É—Å—Ç–∞, –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è–º–∏ –¥–æ –∫–æ–Ω—Ü–∞ –∫—É—Ä—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ **–∑–∞—á—ë—Ç / –Ω–µ –∑–∞—á—ë—Ç**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24208b",
   "metadata": {},
   "source": [
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö **lenta-ru-news** —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `Corus` –∏–ª–∏ –ª—é–±—ã–º –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ —Ç–æ–ø–∏–∫–∞–º (–ø—Ä–∏–≥–æ–¥—è—Ç—Å—è –∞—Ç—Ä–∏–±—É—Ç—ã `title`, `text`, `topic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e0d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (4.3.3)\n",
      "Requirement already satisfied: corus in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: razdel in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: pymorphy3 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (2.0.4)\n",
      "Requirement already satisfied: fasttext in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.9.3)\n",
      "Requirement already satisfied: navec in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: nltk in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (3.9.1)\n",
      "Requirement already satisfied: bs4 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: requests in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (2.32.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from pymorphy3) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from fasttext) (3.0.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from fasttext) (75.6.0)\n",
      "Requirement already satisfied: click in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from nltk) (2025.7.29)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from dawg2-python>=0.8.0->pymorphy3) (4.14.1)\n",
      "Requirement already satisfied: wrapt in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim corus razdel pymorphy3 fasttext navec nltk bs4 requests scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f608d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-30 08:35:08--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A30%3A55Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A30%3A45Z&ske=2025-07-30T06%3A30%3A55Z&sks=b&skv=2018-11-09&sig=RI3O1rziO9jNrqQa0pE2ERRU7LatzIu%2BDm46KsrRLOk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NDAwOCwibmJmIjoxNzUzODUzNzA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.a5EGX6nrL9EJfGAPpUo5LA-_BouHLHYkMxsxf4CPGCI&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-07-30 08:35:08--  https://release-assets.githubusercontent.com/github-production-release-asset/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T06%3A30%3A55Z&rscd=attachment%3B+filename%3Dlenta-ru-news.csv.gz&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T05%3A30%3A45Z&ske=2025-07-30T06%3A30%3A55Z&sks=b&skv=2018-11-09&sig=RI3O1rziO9jNrqQa0pE2ERRU7LatzIu%2BDm46KsrRLOk%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg1NDAwOCwibmJmIjoxNzUzODUzNzA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.a5EGX6nrL9EJfGAPpUo5LA-_BouHLHYkMxsxf4CPGCI&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 527373240 (503M) [application/octet-stream]\n",
      "Saving to: ‚Äòlenta-ru-news.csv.gz.4‚Äô\n",
      "\n",
      "lenta-ru-news.csv.g 100%[===================>] 502.94M  6.35MB/s    in 75s     \n",
      "\n",
      "2025-07-30 08:36:24 (6.69 MB/s) - ‚Äòlenta-ru-news.csv.gz.4‚Äô saved [527373240/527373240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d1401f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LentaRecord(\n",
       "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
       "    title='–ù–∞–∑–≤–∞–Ω—ã —Ä–µ–≥–∏–æ–Ω—ã –†–æ—Å—Å–∏–∏ —Å\\xa0—Å–∞–º–æ–π –≤—ã—Å–æ–∫–æ–π —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç—å—é –æ—Ç\\xa0—Ä–∞–∫–∞',\n",
       "    text='–í–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –ø–æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º –¢–∞—Ç—å—è–Ω–∞ –ì–æ–ª–∏–∫–æ–≤–∞ —Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞, –≤ –∫–∞–∫–∏—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö –†–æ—Å—Å–∏–∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞–∏–±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∞—è —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç—å –æ—Ç —Ä–∞–∫–∞, —Å–æ–æ–±—â–∞–µ—Ç –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏. –ü–æ —Å–ª–æ–≤–∞–º –ì–æ–ª–∏–∫–æ–≤–æ–π, —á–∞—â–µ –≤—Å–µ–≥–æ –æ–Ω–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è —Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å –ø—Ä–∏—á–∏–Ω–æ–π —Å–º–µ—Ä—Ç–∏ –≤ –ü—Å–∫–æ–≤—Å–∫–æ–π, –¢–≤–µ—Ä—Å–∫–æ–π, –¢—É–ª—å—Å–∫–æ–π –∏ –û—Ä–ª–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç—è—Ö, –∞ —Ç–∞–∫–∂–µ –≤ –°–µ–≤–∞—Å—Ç–æ–ø–æ–ª–µ. –í–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –Ω–∞–ø–æ–º–Ω–∏–ª–∞, —á—Ç–æ –≥–ª–∞–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç–∏ –≤ –†–æ—Å—Å–∏–∏ ‚Äî —Ä–∞–∫ –∏ –±–æ–ª–µ–∑–Ω–∏ —Å–∏—Å—Ç–µ–º—ã –∫—Ä–æ–≤–æ–æ–±—Ä–∞—â–µ–Ω–∏—è. –í –Ω–∞—á–∞–ª–µ –≥–æ–¥–∞ —Å—Ç–∞–ª–æ –∏–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç—å –æ—Ç –æ–Ω–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π —Å—Ä–µ–¥–∏ —Ä–æ—Å—Å–∏—è–Ω —Å–Ω–∏–∑–∏–ª–∞—Å—å –≤–ø–µ—Ä–≤—ã–µ –∑–∞ —Ç—Ä–∏ –≥–æ–¥–∞. –ü–æ –¥–∞–Ω–Ω—ã–º –†–æ—Å—Å—Ç–∞—Ç–∞, –≤ 2017 –≥–æ–¥—É –æ—Ç —Ä–∞–∫–∞ —É–º–µ—Ä–ª–∏ 289 —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫. –≠—Ç–æ –Ω–∞ 3,5 –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –º–µ–Ω—å—à–µ, —á–µ–º –≥–æ–¥–æ–º —Ä–∞–Ω–µ–µ.',\n",
       "    topic='–†–æ—Å—Å–∏—è',\n",
       "    tags='–û–±—â–µ—Å—Ç–≤–æ',\n",
       "    date=None\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corus import load_lenta\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "corpus = load_lenta(path)\n",
    "next(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24a290",
   "metadata": {},
   "source": [
    "2. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –∫ –æ–±—É—á–µ–Ω–∏—é ‚Äî **2 –±–∞–ª–ª–∞**\n",
    "\n",
    "* –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ: —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é, –Ω–∞ –≤–∞—à –≤–∑–≥–ª—è–¥, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤ (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –æ—á–∏—Å—Ç–∫–∞, —Å—Ç–µ–º–º–∏–Ω–≥/–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Ç.–ø.) –∏ —Ç–∞—Ä–≥–µ—Ç–∞.\n",
    "* *Hint:* –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å—Å—è –Ω–µ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º, –∞ –µ–≥–æ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ–π —á–∞—Å—Ç—å—é, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑–º–µ—Ä–∞ `100_000`.\n",
    "* –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å, –∏ –ø–æ—á–µ–º—É.\n",
    "* –†–∞–∑–¥–µ–ª–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ —Å–æ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –≤ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ `60/20/20`. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞—Ç—Ä–∏–±—É—Ç `topic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e561657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ê–≤—Å—Ç—Ä–∏—è –Ω–µ¬†–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –≤–∏–Ω—ã —Ä–æ—Å—Å...</td>\n",
       "      <td>–ê–≤—Å—Ç—Ä–∏–π—Å–∫–∏–µ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –Ω–µ –ø—Ä–µ–¥—Å...</td>\n",
       "      <td>–°–ø–æ—Ä—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–∞–º–æ–µ —Å—á–∞—Å—Ç–ª–∏–≤–æ–µ –º–µ—Å—Ç–æ –Ω–∞¬†–ø–ª–∞–Ω–µ—Ç–µ</td>\n",
       "      <td>–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏ Instagram –ø—Ä–æ–∞–Ω–∞–ª–∏–∑...</td>\n",
       "      <td>–ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–í –°–®–ê —Ä–∞—Å–∫—Ä—ã–ª–∏ —Å—É–º–º—É —Ä–∞—Å—Ö–æ–¥–æ–≤ –Ω–∞¬†—Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ...</td>\n",
       "      <td>–° –Ω–∞—á–∞–ª–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç...</td>\n",
       "      <td>–ú–∏—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–•–∞–∫–µ—Ä—ã —Ä–∞—Å—Å–∫–∞–∑–∞–ª–∏ –æ¬†–ø–ª–∞–Ω–∞—Ö –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –∑–∞–º–∏...</td>\n",
       "      <td>–•–∞–∫–µ—Ä—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ Anonymous –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –Ω...</td>\n",
       "      <td>–ú–∏—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ê—Ä—Ö–∏–µ–ø–∏—Å–∫–æ–ø –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π –£–ü–¶ –æ—Ç–∫–∞–∑–∞–ª—Å—è –ø—Ä–∏–π—Ç–∏ ...</td>\n",
       "      <td>–ê—Ä—Ö–∏–µ–ø–∏—Å–∫–æ–ø –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π –£–∫—Ä–∞–∏–Ω—Å–∫–æ–π –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω...</td>\n",
       "      <td>–ë—ã–≤—à–∏–π –°–°–°–†</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  –ê–≤—Å—Ç—Ä–∏—è –Ω–µ¬†–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –≤–∏–Ω—ã —Ä–æ—Å—Å...   \n",
       "1       –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–∞–º–æ–µ —Å—á–∞—Å—Ç–ª–∏–≤–æ–µ –º–µ—Å—Ç–æ –Ω–∞¬†–ø–ª–∞–Ω–µ—Ç–µ   \n",
       "2  –í –°–®–ê —Ä–∞—Å–∫—Ä—ã–ª–∏ —Å—É–º–º—É —Ä–∞—Å—Ö–æ–¥–æ–≤ –Ω–∞¬†—Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ...   \n",
       "3  –•–∞–∫–µ—Ä—ã —Ä–∞—Å—Å–∫–∞–∑–∞–ª–∏ –æ¬†–ø–ª–∞–Ω–∞—Ö –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –∑–∞–º–∏...   \n",
       "4  –ê—Ä—Ö–∏–µ–ø–∏—Å–∫–æ–ø –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π –£–ü–¶ –æ—Ç–∫–∞–∑–∞–ª—Å—è –ø—Ä–∏–π—Ç–∏ ...   \n",
       "\n",
       "                                                text        topic  \n",
       "0  –ê–≤—Å—Ç—Ä–∏–π—Å–∫–∏–µ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –Ω–µ –ø—Ä–µ–¥—Å...        –°–ø–æ—Ä—Ç  \n",
       "1  –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–µ—Ç–∏ Instagram –ø—Ä–æ–∞–Ω–∞–ª–∏–∑...  –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è  \n",
       "2  –° –Ω–∞—á–∞–ª–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç...          –ú–∏—Ä  \n",
       "3  –•–∞–∫–µ—Ä—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ Anonymous –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –Ω...          –ú–∏—Ä  \n",
       "4  –ê—Ä—Ö–∏–µ–ø–∏—Å–∫–æ–ø –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π –£–∫—Ä–∞–∏–Ω—Å–∫–æ–π –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω...  –ë—ã–≤—à–∏–π –°–°–°–†  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "## –ß—Ç–µ–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö 100_000 —Å—Ç–∞—Ç–µ–π\n",
    "records = []\n",
    "for i, article in enumerate(corpus):\n",
    "    if i >= 100_000:\n",
    "        break\n",
    "    records.append({'title': article.title, 'text': article.text, 'topic': article.topic})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb8b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 59999\n",
      "Val: 20000\n",
      "Test: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ\n",
    "class_counts = df['topic'].value_counts()\n",
    "\n",
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å—ã —Å ‚â• 3 –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "valid_topics = class_counts[class_counts >= 3].index\n",
    "\n",
    "# –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º DataFrame\n",
    "df_filtered = df[df['topic'].isin(valid_topics)].reset_index(drop=True)\n",
    "\n",
    "# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–µ–ª–∞—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ\n",
    "X = df_filtered['text']\n",
    "y = df_filtered['topic']\n",
    "\n",
    "# –ü–µ—Ä–≤—ã–π —Å–ø–ª–∏—Ç: train (60%) –∏ temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# –í—Ç–æ—Ä–æ–π —Å–ø–ª–∏—Ç: validation (20%) –∏ test (20%) –∏–∑ temp (40%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–∑–º–µ—Ä—ã\n",
    "print(f\"Train: {len(X_train)}\")\n",
    "print(f\"Val: {len(X_val)}\")\n",
    "print(f\"Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2a976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sergey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "# NLTK —Ä–µ—Å—É—Ä—Å—ã\n",
    "download('stopwords')\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stopwords=True):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        #print(f'_clean_text {text}')\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'[^–∞-—è—ë\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    def _lemmatize_text(self, text):\n",
    "        #print(f'_lemmatize_text {text}')\n",
    "        words = text.split()\n",
    "        lemmas = [\n",
    "            morph.parse(word)[0].normal_form\n",
    "            for word in words\n",
    "            if (not self.remove_stopwords or word not in russian_stopwords) and len(word) > 2\n",
    "        ]\n",
    "        return ' '.join(lemmas)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [self._lemmatize_text(self._clean_text(text)) for text in X]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56c58c",
   "metadata": {},
   "source": [
    "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å `sklearn.linear_model.LogisticRegression` —Å –¥–≤—É–º—è –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ‚Äî **2 –±–∞–ª–ª–∞**\n",
    "\n",
    "* `sklearn.feature_extraction.text.CountVectorizer`\n",
    "* `sklearn.feature_extraction.text.TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3edfc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def build_pipeline(vectorizer):\n",
    "    return Pipeline([\n",
    "        ('clear', TextCleaner()),\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('clf', LogisticRegression(max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "def evaluate_pipeline(pipeline, X_train, y_train, X_val, y_val, name=\"\"):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    \n",
    "    print(f\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "    print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd806a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è: CountVectorizer\n",
      "Accuracy: 0.7857\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.63      0.54      0.58       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.50      0.49      0.50       398\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.78      0.79      0.78      1362\n",
      "              –î–æ–º       0.81      0.82      0.81       682\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.72      0.73      0.73       981\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.77      0.76      0.77      1387\n",
      "             –ö—Ä—ã–º       0.62      0.58      0.60       132\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.46      0.31      0.37        61\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.83      0.84      0.83      1316\n",
      "              –ú–∏—Ä       0.80      0.81      0.80      2884\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.83      0.81      0.82      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.74      0.74      0.74       644\n",
      "           –†–æ—Å—Å–∏—è       0.74      0.75      0.74      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.71      0.68      0.70      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.95      0.95      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.89      0.90      0.89       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.75      0.76      0.76      1537\n",
      "\n",
      "         accuracy                           0.79     20000\n",
      "        macro avg       0.70      0.68      0.69     20000\n",
      "     weighted avg       0.78      0.79      0.79     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è: TfidfVectorizer\n",
      "Accuracy: 0.81085\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.84      0.36      0.51       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.61      0.39      0.48       398\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.82      0.81      0.82      1362\n",
      "              –î–æ–º       0.86      0.80      0.83       682\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.77      0.77      0.77       981\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.80      0.77      0.78      1387\n",
      "             –ö—Ä—ã–º       0.67      0.54      0.60       132\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.63      0.20      0.30        61\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.86      0.87      0.86      1316\n",
      "              –ú–∏—Ä       0.80      0.86      0.83      2884\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.86      0.86      0.86      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.82      0.74      0.78       644\n",
      "           –†–æ—Å—Å–∏—è       0.73      0.79      0.76      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.74      0.70      0.72      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.96      0.96      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.93      0.88      0.91       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.77      0.82      0.79      1537\n",
      "\n",
      "         accuracy                           0.81     20000\n",
      "        macro avg       0.75      0.67      0.70     20000\n",
      "     weighted avg       0.81      0.81      0.81     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "count_pipeline = build_pipeline(\n",
    "    CountVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    ")\n",
    "evaluate_pipeline(count_pipeline, X_train, y_train, X_val, y_val, name=\"CountVectorizer\")\n",
    "\n",
    "# TfidfVectorizer\n",
    "tfidf_pipeline = build_pipeline(\n",
    "    TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    ")\n",
    "evaluate_pipeline(tfidf_pipeline, X_train, y_train, X_val, y_val, name=\"TfidfVectorizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b688d",
   "metadata": {},
   "source": [
    "4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ, –ø–æ–¥–æ–±—Ä–∞–≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ ‚Äî **1 –±–∞–ª–ª**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ba9117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 6666\n",
      "max_resources_: 59999\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 24\n",
      "n_resources: 6666\n",
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 8\n",
      "n_resources: 19998\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 3\n",
      "n_resources: 59994\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "üîç –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
      "{'clf__C': 5.0, 'vectorizer': TfidfVectorizer(), 'vectorizer__max_features': 2000, 'vectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "üìä –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\n",
      "Accuracy: 0.81325\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.79      0.48      0.60       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.58      0.45      0.50       398\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.82      0.81      0.82      1362\n",
      "              –î–æ–º       0.87      0.83      0.85       682\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.76      0.77      0.76       981\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.80      0.78      0.79      1387\n",
      "             –ö—Ä—ã–º       0.73      0.61      0.66       132\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.58      0.31      0.40        61\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.86      0.86      0.86      1316\n",
      "              –ú–∏—Ä       0.81      0.85      0.83      2884\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.86      0.85      0.85      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.82      0.77      0.79       644\n",
      "           –†–æ—Å—Å–∏—è       0.74      0.79      0.77      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.75      0.70      0.72      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.96      0.96      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.91      0.90      0.91       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.77      0.82      0.80      1537\n",
      "\n",
      "         accuracy                           0.81     20000\n",
      "        macro avg       0.74      0.70      0.72     20000\n",
      "     weighted avg       0.81      0.81      0.81     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer': [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vectorizer__max_features': [1000, 2000],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__C': [0.1, 1.0, 5.0]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clear', TextCleaner()),\n",
    "    ('vectorizer', CountVectorizer()),  # placeholder (–±—É–¥–µ—Ç –∑–∞–º–µ–Ω—ë–Ω –≤ GridSearch)\n",
    "    ('clf', LogisticRegression(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "grid = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=2,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"üîç –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"\\nüìä –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:\")\n",
    "y_pred = grid.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33599765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044771978420227"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b303519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         3\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.69      0.53      0.60       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.62      0.46      0.53       399\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.84      0.81      0.82      1362\n",
      "              –î–æ–º       0.86      0.83      0.84       681\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.78      0.76      0.77       980\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.78      0.76      0.77      1387\n",
      "             –ö—Ä—ã–º       0.77      0.66      0.71       133\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.66      0.37      0.47        62\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.86      0.86      0.86      1315\n",
      "              –ú–∏—Ä       0.81      0.87      0.84      2885\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.87      0.86      0.86      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.84      0.78      0.81       645\n",
      "           –†–æ—Å—Å–∏—è       0.76      0.79      0.78      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.75      0.74      0.75      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.96      0.96      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.92      0.89      0.90       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.77      0.80      0.79      1536\n",
      "\n",
      "         accuracy                           0.82     20000\n",
      "        macro avg       0.75      0.71      0.73     20000\n",
      "     weighted avg       0.82      0.82      0.82     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = grid.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad1764",
   "metadata": {},
   "source": [
    "5. –û–±—É—á–∏—Ç–µ **word2vec**-—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `gensim` ‚Äî **2 –±–∞–ª–ª–∞**\n",
    "\n",
    "* –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ –ø–æ—á–µ–º—É.\n",
    "* –í–∏–∑—É–∞–ª—å–Ω–æ –æ—Ü–µ–Ω–∏—Ç–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ (intrinsic) –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–∏–≤—à–∏—Ö—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥—ã gensim ‚Äî `doesnt_match`, `most_similar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e57e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "from corus import load_lenta\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99ffede",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(path)\n",
    "data = [next(records).text for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3bbea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã –≤ —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "tokenized_corpus = [simple_preprocess(doc) for doc in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e655f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=tokenized_corpus,  # –∫–æ—Ä–ø—É—Å\n",
    "    vector_size=100,             # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤ (–æ–±—ã—á–Ω–æ 100‚Äì300)\n",
    "    window=5,                    # —à–∏—Ä–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–∫–Ω–æ –≤–æ–∫—Ä—É–≥ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞)\n",
    "    min_count=5,                 # –∏—Å–∫–ª—é—á–∞–µ–º —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞\n",
    "    workers=4,                   # —á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤\n",
    "    sg=1,                        # 1 ‚Äî skip-gram; 0 ‚Äî CBOW\n",
    "    epochs=10,                   # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03cd5a6",
   "metadata": {},
   "source": [
    "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
    "- vector_size=100 ‚Äî —ç—Ç–æ —Ä–∞–∑—É–º–Ω—ã–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é –Ω–∞ —Å—Ä–µ–¥–Ω–∏—Ö –∫–æ—Ä–ø—É—Å–∞—Ö.\n",
    "- window=5 ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —è–∑—ã–∫–æ–≤—ã—Ö –∑–∞–¥–∞—á; –±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n",
    "- min_count=5 ‚Äî —É–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ä–µ–∂–µ; —Ç–∞–∫ –º–æ–¥–µ–ª—å –Ω–µ –±—É–¥–µ—Ç \"–∑–∞—à—É–º–ª–µ–Ω–∞\" —Ä–µ–¥–∫–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–º–∏—Å—è —Å–ª–æ–≤–∞–º–∏.\n",
    "- workers=4 ‚Äî —Ä–∞–≤–µ–Ω —á–∏—Å–ª—É —è–¥–µ—Ä, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞ –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö –º–∞—à–∏–Ω–∞—Ö.\n",
    "- sg=1 ‚Äî skip-gram –ø–æ–¥—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –Ω–∞–º –≤–∞–∂–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤ (–æ–±—ã—á–Ω–æ —Ç–∞–∫).\n",
    "- epochs=10 ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å ‚Äú–ø—Ä–æ—É—á–∏–ª–∞‚Äù –∫–æ—Ä–ø—É—Å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45a04cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå most_similar('—Ä–æ—Å—Å–∏—è'):\n",
      "[('—Å—Ç—Ä–∞–Ω–∞', 0.7508721947669983), ('—É–∫—Ä–∞–∏–Ω–∞', 0.7415850758552551), ('–±–µ–ª–æ—Ä—É—Å—Å–∏—è', 0.7095548510551453), ('—Ç—É—Ä—Ü–∏—è', 0.7058400511741638), ('–º–æ—Å–∫–≤–∞', 0.6686978340148926)]\n",
      "\n",
      "‚ùå doesnt_match(['–º–æ—Å–∫–≤–∞', '–ø–∞—Ä–∏–∂', '–±–µ—Ä–ª–∏–Ω', '–∫–æ—à–∫–∞']):\n",
      "–∫–æ—à–∫–∞\n"
     ]
    }
   ],
   "source": [
    "# –°–∞–º–æ–µ –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ —Å–ª–æ–≤–æ\n",
    "print(\"üìå most_similar('—Ä–æ—Å—Å–∏—è'):\")\n",
    "print(w2v_model.wv.most_similar('—Ä–æ—Å—Å–∏—è', topn=5))\n",
    "\n",
    "# –°–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç\n",
    "print(\"\\n‚ùå doesnt_match(['–º–æ—Å–∫–≤–∞', '–ø–∞—Ä–∏–∂', '–±–µ—Ä–ª–∏–Ω', '–∫–æ—à–∫–∞']):\")\n",
    "print(w2v_model.wv.doesnt_match(['–º–æ—Å–∫–≤–∞', '–ø–∞—Ä–∏–∂', '–±–µ—Ä–ª–∏–Ω', '–∫–æ—à–∫–∞']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ed1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec_lenta.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db3ebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, vector_size=100):\n",
    "        self.model = model\n",
    "        self.vector_size = model.vector_size\n",
    "\n",
    "    #def fit(self, X, y=None):\n",
    "    #    return self\n",
    "    def fit(self, X, y=None):\n",
    "        #tokenized_corpus = [doc.split() for doc in X]\n",
    "        #self.model = Word2Vec(\n",
    "        #    sentences=tokenized_corpus,  # –∫–æ—Ä–ø—É—Å\n",
    "        #    vector_size=self.vector_size,             # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤ (–æ–±—ã—á–Ω–æ 100‚Äì300)\n",
    "        #    window=5,                    # —à–∏—Ä–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–∫–Ω–æ –≤–æ–∫—Ä—É–≥ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞)\n",
    "        #    min_count=5,                 # –∏—Å–∫–ª—é—á–∞–µ–º —Ä–µ–¥–∫–∏–µ —Å–ª–æ–≤–∞\n",
    "        #    workers=4,                   # —á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤\n",
    "        #    sg=1,                        # 1 ‚Äî skip-gram; 0 ‚Äî CBOW\n",
    "        #    epochs=10,                   # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "        #    seed=42\n",
    "        #)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self._document_vector(doc) for doc in X])\n",
    "\n",
    "    def _document_vector(self, doc):\n",
    "        words = doc.split()\n",
    "        vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n",
    "        if vectors:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(self.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d76b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è: Word2VecVectorizer\n",
      "Accuracy: 0.7626\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.69      0.37      0.49       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.47      0.25      0.33       398\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.79      0.77      0.78      1362\n",
      "              –î–æ–º       0.79      0.73      0.76       682\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.70      0.70      0.70       981\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.73      0.71      0.72      1387\n",
      "             –ö—Ä—ã–º       0.58      0.29      0.38       132\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.38      0.10      0.16        61\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.83      0.83      0.83      1316\n",
      "              –ú–∏—Ä       0.77      0.83      0.80      2884\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.81      0.81      0.81      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.75      0.66      0.70       644\n",
      "           –†–æ—Å—Å–∏—è       0.68      0.74      0.71      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.66      0.62      0.64      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.95      0.95      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.91      0.86      0.89       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.70      0.79      0.74      1537\n",
      "\n",
      "         accuracy                           0.76     20000\n",
      "        macro avg       0.68      0.61      0.63     20000\n",
      "     weighted avg       0.76      0.76      0.76     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Word2VecVectorizer\n",
    "w2v_pipeline = build_pipeline(\n",
    "    Word2VecVectorizer(w2v_model)\n",
    ")\n",
    "evaluate_pipeline(w2v_pipeline, X_train, y_train, X_val, y_val, name=\"Word2VecVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b1ea9",
   "metadata": {},
   "source": [
    "6. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ `navec` –∏–ª–∏ `rusvectores` (–Ω–∞ –≤–∞—à –≤–∫—É—Å) ‚Äî **1 –±–∞–ª–ª**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4361ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-30 10:04:17--  https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
      "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243\n",
      "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26634240 (25M) [application/x-tar]\n",
      "Saving to: ‚Äònavec_news_v1_1B_250K_300d_100q.tar.1‚Äô\n",
      "\n",
      "navec_news_v1_1B_25 100%[===================>]  25.40M  10.2MB/s    in 2.5s    \n",
      "\n",
      "2025-07-30 10:04:21 (10.2 MB/s) - ‚Äònavec_news_v1_1B_250K_300d_100q.tar.1‚Äô saved [26634240/26634240]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5742206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "420f7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13068067, -0.12051002, -0.05782367,  0.07967507,  0.08338855,\n",
       "        0.59920526,  0.4020081 , -1.0838276 ,  0.12556174,  0.17060532,\n",
       "        0.16637331, -0.00257014,  0.51296437,  0.17175263, -0.40394753],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "navec['—á–µ–ª–æ–≤–µ–∫'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16631e4",
   "metadata": {},
   "source": [
    "7. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å `sklearn.linear_model.LogisticRegression` —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏, —Å—Ä–∞–≤–Ω–∏—Ç–µ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ –º–µ–∂–¥—É —Å–æ–±–æ–π –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ ‚Äî **1 –±–∞–ª–ª**\n",
    "\n",
    "* –≤–∞—à–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ `w2v`\n",
    "* –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ `navec`/`rusvectores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f819bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class NavecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, navec):\n",
    "        self.navec = navec\n",
    "        self.vector_size = navec['–ø—Ä–∏–º–µ—Ä'].shape[0]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self._text_vector(text) for text in X])\n",
    "\n",
    "    def _text_vector(self, text):\n",
    "        tokens = text.split()\n",
    "        vectors = [self.navec[token] for token in tokens if token in self.navec]\n",
    "        if vectors:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(self.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64379579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è: NavecVectorizer\n",
      "Accuracy: 0.7827\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                        0.00      0.00      0.00         4\n",
      "   69-—è –ø–∞—Ä–∞–ª–ª–µ–ª—å       0.76      0.53      0.62       163\n",
      "           –ë–∏–∑–Ω–µ—Å       0.51      0.34      0.41       398\n",
      "      –ë—ã–≤—à–∏–π –°–°–°–†       0.82      0.81      0.82      1362\n",
      "              –î–æ–º       0.81      0.75      0.78       682\n",
      "         –ò–∑ –∂–∏–∑–Ω–∏       0.72      0.70      0.71       981\n",
      "   –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –°–ú–ò       0.75      0.72      0.73      1387\n",
      "             –ö—Ä—ã–º       0.67      0.52      0.58       132\n",
      "    –ö—É–ª—å—Ç–ø—Ä–æ—Å–≤–µ—Ç        0.47      0.30      0.36        61\n",
      "         –ö—É–ª—å—Ç—É—Ä–∞       0.84      0.85      0.85      1316\n",
      "              –ú–∏—Ä       0.79      0.84      0.81      2884\n",
      "  –ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞       0.83      0.83      0.83      1129\n",
      "      –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è       0.78      0.72      0.75       644\n",
      "           –†–æ—Å—Å–∏—è       0.71      0.76      0.73      3030\n",
      "–°–∏–ª–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã       0.69      0.64      0.67      1385\n",
      "            –°–ø–æ—Ä—Ç       0.96      0.95      0.96      2009\n",
      "         –¶–µ–Ω–Ω–æ—Å—Ç–∏       0.88      0.87      0.88       896\n",
      "        –≠–∫–æ–Ω–æ–º–∏–∫–∞       0.74      0.80      0.77      1537\n",
      "\n",
      "         accuracy                           0.78     20000\n",
      "        macro avg       0.71      0.66      0.68     20000\n",
      "     weighted avg       0.78      0.78      0.78     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/sergey/Projects/GigaSchool/llm-engineer/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# NavecVectorizer\n",
    "navec_pipeline = build_pipeline(\n",
    "    NavecVectorizer(navec)\n",
    ")\n",
    "evaluate_pipeline(navec_pipeline, X_train, y_train, X_val, y_val, name=\"NavecVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284cd36",
   "metadata": {},
   "source": [
    "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞–º–∏\n",
    "\n",
    "–í —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –¥–≤—É—Ö —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:\n",
    "\n",
    "| –ú–æ–¥–µ–ª—å               | Accuracy | Macro F1 | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏                            |\n",
    "|----------------------|----------|----------|----------------------------------------|\n",
    "| Word2VecVectorizer   | 0.7626   | 0.63     | –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ–±—É—á–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –Ω–æ–≤–æ—Å—Ç–µ–π. –•–æ—Ä–æ—à–æ –æ—Ç—Ä–∞–∂–∞—é—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫—É, –Ω–æ —Ö—É–∂–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å —Ä–µ–¥–∫–∏–º–∏ –∏ –æ–±—â–∏–º–∏ —Å–ª–æ–≤–∞–º–∏. |\n",
    "| NavecVectorizer      | 0.7827   | 0.68     | –ì–æ—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ –±–æ–ª—å—à–æ–º –∫–æ—Ä–ø—É—Å–µ (Navec, —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ). –õ—É—á—à–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ä–µ–¥–∫–∏—Ö –∏ —à–∏—Ä–æ–∫–æ—É–ø–æ—Ç—Ä–µ–±–∏–º—ã—Ö —Å–ª–æ–≤, —É—Å—Ç–æ–π—á–∏–≤–µ–µ –Ω–∞ –º–∞–ª—ã—Ö –∫–ª–∞—Å—Å–∞—Ö. |\n",
    "\n",
    "### –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã\n",
    "\n",
    "- **NavecVectorizer** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∏ f1-–º–∞–∫—Ä–æ –≤–æ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–∞—Ö.\n",
    "- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ Word2Vec —É—Å—Ç—É–ø–∞—é—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –Ω–∞ –º–∞–ª–æ—á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö –∏ —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤–∞—Ö, –Ω–æ –º–æ–≥—É—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è –æ—á–µ–Ω—å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π.\n",
    "- –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –≥–æ—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (Navec –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddd7fe",
   "metadata": {},
   "source": [
    "8. –§–∏–Ω–∞–ª—å–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ ‚Äî **1 –±–∞–ª–ª**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524179d8",
   "metadata": {},
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "\n",
    "| –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä         | Accuracy | Macro F1 | –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ                                   |\n",
    "|----------------------|----------|----------|----------------------------------------------------|\n",
    "| TfidfVectorizer      | 0.8109   | 0.70     | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è TF-IDF –º–æ–¥–µ–ª—å, –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —Ç–µ—Å—Ç–µ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ macro f1 |\n",
    "| CountVectorizer      | 0.7857   | 0.69     | –ë–∞–∑–æ–≤–∞—è bag-of-words –º–æ–¥–µ–ª—å                         |\n",
    "| Word2VecVectorizer   | 0.7626   | 0.63     | –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ Word2Vec –Ω–∞ –≤–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ    |\n",
    "| NavecVectorizer      | 0.7827   | 0.68     | –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ Navec              |\n",
    "\n",
    "---\n",
    "\n",
    "## –ö—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã\n",
    "\n",
    "- **TfidfVectorizer** –ø–æ–∫–∞–∑–∞–ª –Ω–∞–∏–≤—ã—Å—à–µ–µ –∏—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (accuracy –∏ macro f1), —á—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è –∑–∞–¥–∞—á —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏ –∫–æ–≥–¥–∞ –≤ –∫–æ—Ä–ø—É—Å–µ –º–Ω–æ–≥–æ —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö, —Ö–æ—Ä–æ—à–æ —Ä–∞–∑–ª–∏—á–∏–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "- **CountVectorizer** –Ω–µ–º–Ω–æ–≥–æ —É—Å—Ç—É–ø–∞–µ—Ç TF-IDF, –Ω–æ –æ–ø–µ—Ä–µ–∂–∞–µ—Ç –æ–±–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö.\n",
    "- –û–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (Word2Vec –∏ Navec) —É—Å—Ç—É–ø–∞—é—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞–º, –Ω–æ **Navec** —É–≤–µ—Ä–µ–Ω–Ω–æ –ª—É—á—à–µ —Å–∞–º–æ–¥–µ–ª—å–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (Word2Vec), –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ macro f1.\n",
    "- **Word2VecVectorizer** –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π, –Ω–æ —Å—Ç—Ä–∞–¥–∞–µ—Ç –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∏–ª–∏ –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Å–∞—Ö.\n",
    "- **NavecVectorizer** —Å—Ç–∞–±–∏–ª—å–Ω–æ –ª—É—á—à–µ Word2Vec, –Ω–æ –≤—Å—ë –µ—â—ë —É—Å—Ç—É–ø–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—É, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–º—É –Ω–∞ TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc750ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bdc6ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb23b57",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
